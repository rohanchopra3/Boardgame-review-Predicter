{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kmpKJPyz78oz"
   },
   "source": [
    "# NLP using Neural Networks\n",
    "\n",
    "This project applies state of the art machine learning technique, Neural Networks to create a multi class text classifier. The dataset contains 13 million board games reviews from different users all around the word. Yes the data set is very large and training this large dataset might be a problem .However , thanks to google , not only for tensorflow but they have a very powerful cloud notebook , which uses GPUs and TPUs and can be used to run Machine learning models for free.\n",
    "\n",
    "colab by google :- https://colab.research.google.com/notebooks/intro.ipynb#recent=true\n",
    "\n",
    "#### Why Neural networks ?\n",
    "\n",
    "The reason I choose neural networks for this project because of two major reasons. Firstly , I have never done NLP using neural networks and I wanted to go out of my way to do something that is neither taught to me any class nor I have had experience with before . Secondly, I have heard all the hype regarding how powerfull neural Networks are and what is the better way of exploring this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "juP4M8hE78o3"
   },
   "source": [
    "## Review predictor\n",
    "\n",
    "This project is trained and tested using a large dataset of 13 million boardgames reviews. The model that is created is used to deploy a realtime predictor on a website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yCtaq6W_78o4"
   },
   "source": [
    "## Importing libraries\n",
    "\n",
    "First step is to import all the libraries that are needed for this project . Some the libraries I have used are :-\n",
    "1. Tensorflow and Keras : For creating and testing neural networks models. \n",
    "2. sklearn: For splitting the data.\n",
    "3. matplotlib: For data visualisation.\n",
    "4. nltk : For cleaning the data using stopwords.\n",
    "5. re: For creating regular expressions.\n",
    "6. Numpy: For mathematical operations.\n",
    "7. Pandas: For reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "6A6Brzm7tGup",
    "outputId": "4109ce33-80b8-4c69-f73f-03c4e990da20"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten, Input, Reshape, Concatenate,Conv2D,MaxPool2D,concatenate ,Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1,l2,l1_l2\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "## Plot\n",
    "import  matplotlib.pyplot as plt\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "# Other\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3cACFt6QChw6",
    "outputId": "dc9473f5-b1aa-4a54-8bdd-8884d50c8b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgnAw58H78pO"
   },
   "source": [
    "## Exploring the data\n",
    "\n",
    "In order to process the data we first need to explore it , understand it , find patterns and finally then we can process the data to our model.\n",
    "I am using pandas to read the CSV file and to apply certain operations on it. Pandas offer a fast yet equally powerfull data processing library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdUc4qbz78pP"
   },
   "source": [
    "### 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3iA-CIstGu9"
   },
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"/content/drive/My Drive/reviews.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NIEFrJKo78pZ"
   },
   "source": [
    "### 2. Displaying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "UgFPYHUCtGvX",
    "outputId": "8df21ce8-68cf-4e02-9fdd-1e7051b755db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rating                                            comment\n",
       "0           0    10.0                                                NaN\n",
       "1           1    10.0                                                NaN\n",
       "2           2    10.0  Currently, this sits on my list as my favorite...\n",
       "3           3    10.0  I know it says how many plays, but many, many ...\n",
       "4           4    10.0                                                NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19MkYoT478pg"
   },
   "source": [
    "### 3. Data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Czk22XwW78ph",
    "outputId": "2c37872e-d7f9-48ef-f60a-ee0782663e9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.317007e+07</td>\n",
       "      <td>1.317007e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.585036e+06</td>\n",
       "      <td>7.023914e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.801873e+06</td>\n",
       "      <td>1.602762e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.401300e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.292518e+06</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.585036e+06</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.877554e+06</td>\n",
       "      <td>8.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.317007e+07</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        rating\n",
       "count  1.317007e+07  1.317007e+07\n",
       "mean   6.585036e+06  7.023914e+00\n",
       "std    3.801873e+06  1.602762e+00\n",
       "min    0.000000e+00  1.401300e-45\n",
       "25%    3.292518e+06  6.000000e+00\n",
       "50%    6.585036e+06  7.000000e+00\n",
       "75%    9.877554e+06  8.000000e+00\n",
       "max    1.317007e+07  1.000000e+01"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSuQDW2h78qH"
   },
   "source": [
    "### 4. Finding Null comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "3BnbjjMD78qH",
    "outputId": "2c1b4990-da7f-4dd4-c60e-4439073047d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0  rating comment\n",
      "0                  0    10.0     NaN\n",
      "1                  1    10.0     NaN\n",
      "4                  4    10.0     NaN\n",
      "5                  5    10.0     NaN\n",
      "6                  6    10.0     NaN\n",
      "...              ...     ...     ...\n",
      "13170060    13170060     4.0     NaN\n",
      "13170061    13170061     4.0     NaN\n",
      "13170064    13170064     3.0     NaN\n",
      "13170068    13170068     3.0     NaN\n",
      "13170072    13170072     2.0     NaN\n",
      "\n",
      "[10532317 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(reviews[reviews['comment'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dze3QKPC78rB"
   },
   "source": [
    "### 5. Numer of different ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "SJAhwzhWCcn9",
    "outputId": "6530d38a-9668-4686-d99b-38b85c7e86f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.00000    2977370\n",
      "8.00000    2468632\n",
      "6.00000    1987008\n",
      "9.00000    1158917\n",
      "5.00000     923398\n",
      "            ...   \n",
      "5.26900          1\n",
      "6.77960          1\n",
      "7.08912          1\n",
      "5.48100          1\n",
      "6.79767          1\n",
      "Name: rating, Length: 8202, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(reviews['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGXvN-cz78rE"
   },
   "source": [
    "### 6. Visualising the ratings vs count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "colab_type": "code",
    "id": "r_MsPvvR78rE",
    "outputId": "2b3ab198-9425-432f-c5af-b7066e000128"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAbuElEQVR4nO3df5QfdX3v8eeLkELMIojhbmMSu7mS6lUiaFZ+CPXsYr03CkJ75JcVJBQa5QoBb9CCnoPIqUesBUFQaCoYoMBC+VFS4KJcyJqg/NpgIAnRNppQEpFAAoENGFl43z9m1n5Zvrs7+e7OTL47r8c5c3Z+fGbm/cluvu/vzHzm81FEYGZm1bVT2QGYmVm5nAjMzCrOicDMrOKcCMzMKs6JwMys4pwIzMwqrikTgaSrJG2UtDJj+WMkPSFplaTr847PzKyZqBnfI5D0EaAXuCYi9hmm7AzgJuDQiHhe0n+LiI1FxGlm1gya8oogIpYAm2vXSXqXpLslLZO0VNJ70k1/A3wvIp5P93USMDOr0ZSJYBALgNMjYhZwFvD9dP2fAn8q6aeSHpQ0u7QIzcx2QDuXHcBokNQCfBj4F0n9q3dJf+4MzAA6gKnAEkkzI+KFouM0M9sRjYlEQHJl80JE7Fdn23rgoYh4FVgr6d9JEsMjRQZoZrajGhO3hiLiRZIP+aMBlNg33fyvJFcDSJpEcqvo12XEaWa2I2rKRCDpBuAB4N2S1ks6GfgMcLKkx4BVwJFp8R8BmyQ9ASwGvhQRm8qI28xsR5R781FJ44AeYENEHD5g2y7ANcAsYBNwbESsyzUgMzN7gyKuCM4AVg+y7WTg+YjYG/gO8K0C4jEzsxq5PiyWNBU4DPgG8H/qFDkSOC+dvxm4TJJiiMuUSZMmRVtbW0PxbN26lYkTJza0b7NynavBda6GkdR52bJlz0XEXvW25d1q6GLgy8Bug2yfAjwFEBF9krYAbweeG+yAbW1t9PT0NBRMd3c3HR0dDe3brFznanCdq2EkdZb05GDbcksEkg4HNkbEMkkdIzzWXGAuQGtrK93d3Q0dp7e3t+F9m5XrXA2uczXkVueIyGUCvknShn8d8FvgZeCfB5T5EXBQOr8zyZWAhjrurFmzolGLFy9ueN9m5TpXg+tcDSOpM9ATg3yu5vawOCLOiYipEdEGHAfcFxHHDyi2CDgxnT8qLdN8veCZmTWxwt8slnQ+SWZaBFwJXCtpDUkncscVHY+ZWdUVkggiohvoTufPrVn/O+DoImIwM7P6mvLNYjMzGz1OBGZmFedEYGZWcU4EZmYVN1bGIzCzErSdfWdp5144u1rdS+TJVwRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhXnRGBmVnFOBGZmFedEYGZWcU4EZmYV50RgZlZxTgRmZhWXWyKQtKukhyU9JmmVpK/XKTNH0rOSlqfTKXnFY2Zm9eXZDfU24NCI6JU0Hrhf0v+NiAcHlLsxIk7LMQ4zMxtCbokgIgLoTRfHp1PkdT4zM2tMrs8IJI2TtBzYCNwTEQ/VKfYpSY9LulnStDzjMTOzN1PyxT3nk0h7ALcBp0fEypr1bwd6I2KbpM8Bx0bEoXX2nwvMBWhtbZ3V1dXVUBy9vb20tLQ0tG+zcp2roaw6r9iwpfBz9pu++zj/nrdDZ2fnsohor7etkEQAIOlc4OWI+IdBto8DNkfE7kMdp729PXp6ehqKobu7m46Ojob2bVauczWUVeeyh6r07zk7SYMmgjxbDe2VXgkgaQLwMeAXA8pMrlk8AlidVzxmZlZfnq2GJgNXp9/0dwJuiog7JJ0P9ETEImCepCOAPmAzMCfHeMzMrI48Ww09Dnygzvpza+bPAc7JKwYzMxue3yw2M6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKcyIwM6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKcyIwM6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKy3Pw+l0lPSzpMUmrJH29TpldJN0oaY2khyS15RWPmZnVl+cVwTbg0IjYF9gPmC3pwAFlTgaej4i9ge8A38oxHjMzqyO3RBCJ3nRxfDrFgGJHAlen8zcDH5WkvGIyM7M3y/UZgaRxkpYDG4F7IuKhAUWmAE8BREQfsAV4e54xmZnZGyli4Jf0HE4i7QHcBpweEStr1q8EZkfE+nT5V8ABEfHcgP3nAnMBWltbZ3V1dTUUR29vLy0tLY1Vokm5ztVQVp1XbNhS+Dn7Td99nH/P26Gzs3NZRLTX27bziKLKKCJekLQYmA2srNm0AZgGrJe0M7A7sKnO/guABQDt7e3R0dHRUBzd3d00um+zcp2roaw6zzn7zsLP2W/h7In+PY+SPFsN7ZVeCSBpAvAx4BcDii0CTkznjwLuiyIuUczM7A/yvCKYDFwtaRxJwrkpIu6QdD7QExGLgCuBayWtATYDx+UYj5mZ1ZFbIoiIx4EP1Fl/bs3874Cj84rBzMauFRu2lHJrat0FhxV+zrz5zWIzs4pzIjAzqzgnAjOzihs2EUh6l6Rd0vkOSfP6WwOZmVnzy3JFcAvwmqS9SdryTwOuzzUqMzMrTJZE8Hra/cNfApdGxJdImoaamdkYkCURvCrp0yQvft2RrhufX0hmZlakLIngJOAg4BsRsVbSdODafMMyM7OiZHmhbDLwtxHxCkBErMXjBpiZjRlZrgg+Czwm6UFJ35b0SUlvyzswMzMrxrBXBBFxIoCkd5B0DPc94B1Z9jUzsx3fsB/mko4H/gyYCTwHXAYszTkuMzMrSJZv9RcDvwKuABZHxLpcIzIzs0IN+4wgIiYBfw3sCnxD0sOS3GrIzGyMyNLFxFuBdwJ/ArSRjCL2er5hmZlZUbLcGrq/Zrqsf3xhMzMbG7K0Gno/gKS3RMTL+YdkZmZFynJr6CBJT5CONyxpX0nfzz0yMzMrRJYXyi4G/hewCSAiHgM+kmdQZmZWnEwvhUXEU5JqV7023D6SpgHXAK1AAAsi4pIBZTqA24G16apbI+L8LDGZ2X8pa/xeGxuyJIKnJH0YCEnjgTOA1Rn26wPmR8SjknYDlkm6JyKeGFBuaUQcvn1hm5nZaMlya+jzwBeAKcAGYL90eUgR8XREPJrOv0SSPKY0HqqZmeVBEZH/SaQ2YAmwT0S8WLO+g2QEtPXAb4CzImJVnf3nAnMBWltbZ3V1dTUUR29vLy0tLQ3t26xc52rYuHkLz7xSdhTFap1AKXWeOWX34k+aGsnfdmdn57KIaK+3bdBEIOnLEfH3ki4lucf/BhExL8vJJbUAPyEZz+DWAdveSjICWq+kTwCXRMSMoY7X3t4ePT09WU79Jt3d3XR0dDS0b7Nynavh0utu58IV1eoHcv7MvlLqvO6Cwwo/Z7+R/G1LGjQRDPWv2P8coLFP3eTE40m+8V83MAkA1F4dRMRdkr4vaVJEPNfoOc3MbPsMmggi4t/S2RX99/q3h5JmRlcCqyPiokHK/DHwTESEpP1Jnlls2t5zmZlZ47JcV12YfmDfDNwYESszHvtg4ARghaTl6bqvkPRbRERcQTK+wamS+oBXgOOiiIcWZmb2B1m6mOhME8ExwD+m9/VvjIi/G2a/+wENU+YykvENzMysJFmajxIRv42I75I0JV0OnJtrVGZmVpgsfQ39D0nnSVoJXAr8DJiae2RmZlaILM8IrgK6gP8ZEb/JOR4zMytYlmcEB0maQPqQ18zMxpYst4Y+SfJc4O50eT9Ji/IOzMzMipHlYfF5wP7ACwARsRyYnmNMZmZWoCyJ4NWI2DJgndv6m5mNEVkeFq+S9FfAOEkzgHkkLYfMzGwMyHJFcDrwPmAbcD2wBTgzz6DMzKw4Q14RSBoH3BkRncBXiwnJzMyKNOQVQUS8BrwuqbwOuM3MLFdZnhH0knQcdw+wtX9l1vEIzMxsx5YlEdyaTmZmNgZlebP46iICMTOzcmTqfdTMzMYuJwIzs4obNBFIujb9eUZx4ZiZWdGGuiKYJekdwF9LepukPWunogI0M7N8DfWw+ArgXuC/A8t447CTka4flKRpwDVAa1p+QURcMqCMgEuATwAvA3Mi4tHtrIOZmY3AoIkgHZryu5Iuj4hTGzh2HzA/Ih6VtBuwTNI9EfFETZmPAzPS6QDg8vSnmZkVJEvz0VMl7Qv8WbpqSUQ8nmG/p4Gn0/mXJK0GpgC1ieBI4JqICOBBSXtImpzua2ZmBVDyGTxEAWkeMJf/eqnsL0lu81ya+SRSG7AE2CciXqxZfwdwQUTcny7fC/xtRPQM2H9uGgOtra2zurq6sp76DXp7e2lpaWlo32blOlfDxs1beOaVsqMoVusESqnzzCnl9bgzkr/tzs7OZRHRXm9bljeLTwEOiIitAJK+BTxAMpD9sCS1ALcAZ9Ymge0REQuABQDt7e3R0dHRyGHo7u6m0X2bletcDZdedzsXrsjy33nsmD+zr5Q6r/tMR+Hn7JfX33aW9wgEvFaz/BpvfHA8+I7SeJIkcF1E1OumYgMwrWZ5arrOzMwKkiWd/hB4SNJt6fJfAFcOt1PaIuhKYHVEXDRIsUXAaZK6SB4Sb/HzATOzYmV5WHyRpG7gkHTVSRHx8wzHPhg4gaTn0uXpuq8A70yPewVwF0nT0TUkzUdP2q7ozcxsxDLdYEvb9m9X+/70AfCQt5DS1kJf2J7jmpnZ6KrW0yUzsxFqO/vO0s69cPbEXI7rTufMzCpuyEQgaZykxUUFY2ZmxfOYxWZmFecxi83MKs5jFpuZVVymMYslTQDeGRG/LCAmMzMr0LCthiR9ElgO3J0u7ydpUd6BmZlZMbI0Hz0P2B94ASAiljPMoDRmZtY8siSCVyNiy4B1r+cRjJmZFS/Lw+JVkv4KGCdpBjAP+Fm+YZmZWVGyXBGcDrwP2AbcALwInJlnUGZmVpwsrYZeBr6aDkgTEfFS/mGZmVlRsrQa+pCkFcDjJC+WPSZpVv6hmZlZEbI8I7gS+N8RsRRA0iEkg9W8P8/AzMysGFmeEbzWnwTgD+MM9OUXkpmZFWnQKwJJH0xnfyLpH0keFAdwLNCdf2hmZlaEoW4NXThg+Ws185FDLGZmVoJBE0FEdI7kwJKuAg4HNkbEPnW2dwC3A2vTVbdGxPkjOaeZmW2/YR8WS9oD+CzQVls+QzfUC4HLgGuGKLM0Ig4fNkozM8tNllZDdwEPAivYjq4lImKJpLbGwjIzs6IoYujb/ZIejYgPDllo8H3bgDuGuDV0C7Ae+A1wVkSsGuQ4c4G5AK2trbO6uroaCYfe3l5aWloa2rdZuc7VsHHzFp55pewoitU6gcrVefru4xr+2+7s7FwWEe31tmVJBF8kGaXsDpJuJgCIiM3DnXiYRPBW4PWI6JX0CeCSiJgx3DHb29ujp6dnuGJ1dXd309HR0dC+zcp1roZLr7udC1dkucAfO+bP7KtcnRfOntjw37akQRNBlvcIfg98G3gAWJZOjX0S14iIFyOiN52/CxgvadJIj2tmZtsnSzqdD+wdEc+N5okl/THwTESEpP1JktKm0TyHmZkNL0siWAO8vL0HlnQD0AFMkrSe5D2E8QARcQVwFHCqpD7gFeC4GO4+lZmZjbosiWArsFzSYt74jGDI5qMR8elhtl9G0rzUzMxKlCUR/Gs6mZnZGJRlPIKriwjEzMzKkeXN4rXU6VsoIjyAvZnZGJDl1lBtu9NdgaOBPfMJx8zMijbsewQRsalm2hARFwOHFRCbmZkVIMutodruJXYiuUKo1ut8ZmZjWJYP9NpxCfqAdcAxuURjZmaFy9JqaETjEpiZ2Y4ty62hXYBP8ebxCDyIjJnZGJDl1tDtwBaSzua2DVPWzMyaTJZEMDUiZuceiZmZlSJLN9Q/kzQz90jMzKwUWa4IDgHmpG8YbwMERES8P9fIzMysEFkSwcdzj8LMzEqTpfnok0UEYmZm5cjyjMDMzMYwdxVhNorazr6zlPPOd3MOGwFfEZiZVVxuiUDSVZI2Slo5yHZJ+q6kNZIeH9C5nZmZFSTPK4KFwFAvon0cmJFOc4HLc4zFzMwGkVsiiIglwOYhihwJXBOJB4E9JE3OKx4zM6uvzIfFU4CnapbXp+ueHlhQ0lySqwZaW1vp7u5u6IS9vb0N79usXOdizZ/ZV8p5WyeUd+6yVLHOef1tN0WroYhYACwAaG9vj46OjoaO093dTaP7NivXuVhzSms11MeFK5riv/OoqWKdF86emMvfdpmthjYA02qWp6brzMysQGUmgkXAZ9PWQwcCWyLiTbeFzMwsX7ldV0m6AegAJklaD3wNGA8QEVcAdwGfANYALwMn5RWLmZkNLrdEEBGfHmZ7AF/I6/xmZpaN3yw2M6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKcyIwM6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKcyIwM6s4JwIzs4pzIjAzqzgnAjOzinMiMDOrOCcCM7OKyzURSJot6ZeS1kg6u872OZKelbQ8nU7JMx4zM3uzPAevHwd8D/gYsB54RNKiiHhiQNEbI+K0vOIwM7Oh5XlFsD+wJiJ+HRG/B7qAI3M8n5mZNUARkc+BpaOA2RFxSrp8AnBA7bd/SXOAbwLPAv8OfDEinqpzrLnAXIDW1tZZXV1dDcXU29tLS0tLQ/s2K9e5WCs2bCnlvK0T4JlXSjl1aapY5+m7j2v4b7uzs3NZRLTX25bbraGM/g24ISK2SfoccDVw6MBCEbEAWADQ3t4eHR0dDZ2su7ubRvdtVlWs86XX3c6F928t6ezl/JeaP7OPC1eU/d+5WFWs88LZE3P5/5znraENwLSa5anpuj+IiE0RsS1d/AEwK8d4zMysjjwTwSPADEnTJf0RcBywqLaApMk1i0cAq3OMx8zM6sjtuioi+iSdBvwIGAdcFRGrJJ0P9ETEImCepCOAPmAzMCeveMzMrL5cb7BFxF3AXQPWnVszfw5wTp4xmJnZ0PxmsZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcU5EZiZVZwTgZlZxTkRmJlVXLV6bLJCtZ19ZynnnT+zlNOaNS1fEZiZVZwTgZlZxTkRmJlVnBOBmVnFORGYmVWcE4GZWcW5+egYt2LDFuaU1IzTzJqDrwjMzCrOVwQF8ctVZrajyvWKQNJsSb+UtEbS2XW27yLpxnT7Q5La8ozHzMzeLLdEIGkc8D3g48B7gU9Leu+AYicDz0fE3sB3gG/lFY+ZmdWX5xXB/sCaiPh1RPwe6AKOHFDmSODqdP5m4KOSlGNMZmY2gCIinwNLRwGzI+KUdPkE4ICIOK2mzMq0zPp0+VdpmecGHGsuMDddfDfwywbDmgQ8N2ypscV1rgbXuRpGUuc/iYi96m1oiofFEbEAWDDS40jqiYj2UQipabjO1eA6V0Nedc7z1tAGYFrN8tR0Xd0yknYGdgc25RiTmZkNkGcieASYIWm6pD8CjgMWDSizCDgxnT8KuC/yuldlZmZ15XZrKCL6JJ0G/AgYB1wVEasknQ/0RMQi4ErgWklrgM0kySJPI7691IRc52pwnashlzrn9rDYzMyag7uYMDOrOCcCM7OKq0wiGK67i7FG0jRJiyU9IWmVpDPKjqkIksZJ+rmkO8qOpSiS9pB0s6RfSFot6aCyY8qTpC+mf9MrJd0gadeyY8qDpKskbUzft+pft6ekeyT9R/rzbaNxrkokgozdXYw1fcD8iHgvcCDwhQrUGeAMYHXZQRTsEuDuiHgPsC9juP6SpgDzgPaI2IekIUrejUzKshCYPWDd2cC9ETEDuDddHrFKJAKydXcxpkTE0xHxaDr/EsmHw5Ryo8qXpKnAYcAPyo6lKJJ2Bz5C0gKPiPh9RLxQblS52xmYkL579BbgNyXHk4uIWELSmrJWbbc8VwN/MRrnqkoimAI8VbO8njH+oVgr7dX1A8BD5UaSu4uBLwOvlx1IgaYDzwI/TG+J/UDSxLKDyktEbAD+AfhP4GlgS0T8uNyoCtUaEU+n878FWkfjoFVJBJUlqQW4BTgzIl4sO568SDoc2BgRy8qOpWA7Ax8ELo+IDwBbGaXbBTui9J74kSQJ8B3AREnHlxtVOdKXb0el/X9VEkGW7i7GHEnjSZLAdRFxa9nx5Oxg4AhJ60hu/R0q6Z/LDakQ64H1EdF/tXczSWIYq/4cWBsRz0bEq8CtwIdLjqlIz0iaDJD+3DgaB61KIsjS3cWYknbnfSWwOiIuKjuevEXEORExNSLaSH6/90XEmP+mGBG/BZ6S9O501UeBJ0oMKW//CRwo6S3p3/hHGcMPx+uo7ZbnROD20ThoU/Q+OlKDdXdRclh5Oxg4AVghaXm67isRcVeJMVk+TgeuS7/k/Bo4qeR4chMRD0m6GXiUpGXczxmjXU1IugHoACZJWg98DbgAuEnSycCTwDGjci53MWFmVm1VuTVkZmaDcCIwM6s4JwIzs4pzIjAzqzgnAjOzinMisDFL0pmS3lKzfJekPXI+57fTnjG/PcrH/bykz47mMc36ufmoNa30hSJFRN2+hdK3jNsj4rkCY9oC7BkRrw1RZueI6CsqJrPh+IrAmoqktnRciWuAlcA0SZdL6km/iX89LTePpC+axZIWp+vWSZqUHmO1pH9K9/mxpAlpmQ9JelzS8vTb/co6Mah/m6QVko5N1y8CWoBl/etq9jlP0rWSfkoyTvdekm6R9Eg6HSxppzTGPWr2+w9Jren+Z6Xr3iXpbknLJC2V9J50HIa1aWx7SHpN0kfS8kskzRj1X4aNHRHhyVPTTEAbSe+iB9as2zP9OQ7oBt6fLq8DJtWUWwdMSo/RB+yXrr8JOD6dXwkclM5fAKysE8OngHvS87WSdHswOd3WO0jc5wHLgAnp8vXAIen8O0m6AoFkbIGT0vkDgP9Xs/9Z6fy9wIyaMvel83cD7wMOJ+lW5avALiR985T+u/O0406V6GLCxpwnI+LBmuVjJM0l6TJlMsngQ48Pc4y1EdHf9cYyoC39Jr5bRDyQrr+e5EN1oEOAGyK5/fOMpJ8AH2L4/qsWRcQr6fyfA+9N7m4B8Na0p9gbgXOBH5L0mXRj7QHSMh8G/qVm313Sn0tJxiaYDnwT+BvgJyRJwWxQTgTWjLb2z0iaDpwFfCginpe0EMgydOG2mvnXgAmjGmF9W2vmdyK5qvldbQFJDwB7S9qLZNCRvxtwjJ2AFyJivzrHXwKcSnJL7FzgSyR91SwdlehtzPIzAmt2byX5gN0iqZVkONJ+LwG7ZT1QJCN7vSTpgHTVYEMgLgWOTe/L70XyLfzh7Yz7xySdxQEgab80hgBuAy4iuV20aUCMLwJrJR2d7idJ+6abHya5Wng9TTDLgc+RJAizQTkRWFOLiMdIeqD8BcmtnJ/WbF4A3N3/sDijk4F/SntsnQhsqVPmNpJbT48B9wFfjqQ76O0xD2hPH0w/AXy+ZtuNwPEMuC1U4zPAyZIeA1aRDrsaEdtIRuLrv222lCQRrtjO2Kxi3HzUrIaklojoTefPJnkIfEbJYZnlys8IzN7oMEnnkPzfeBKYU244ZvnzFYGZWcX5GYGZWcU5EZiZVZwTgZlZxTkRmJlVnBOBmVnF/X8kuHXFWVIIcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "reviews.head()\n",
    "reviews['rating'].hist(bins=10)\n",
    "plt.xlabel('rating of review')\n",
    "plt.ylabel('number of reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kpx7EWaJ78rJ"
   },
   "source": [
    "## Data Cleaning\n",
    "\n",
    "After visualising the data we can conlude the following things:-\n",
    "1. The data is unbalanced. Some ratings have more data than others. Like rating 1 Has least data while 7 has the most data.\n",
    "2. The data has null values.\n",
    "3. Text data always have some errors and needs to be cleaned before processing.\n",
    "4. The ratings sections has 8202 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tAsEayq778rJ"
   },
   "source": [
    "### Removing Null values\n",
    "Using the pandas inbuilt function I am removing all the rows with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fU5AmL7XCcog",
    "outputId": "5580a077-1e56-4403-ce54-0d4db4ca4469"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Currently, this sits on my list as my favorite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I know it says how many plays, but many, many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>i will never tire of this game.. Awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>10.0</td>\n",
       "      <td>This is probably the best game I ever played. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Fantastic game. Got me hooked on games all ove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  rating                                            comment\n",
       "2            2    10.0  Currently, this sits on my list as my favorite...\n",
       "3            3    10.0  I know it says how many plays, but many, many ...\n",
       "7            7    10.0           i will never tire of this game.. Awesome\n",
       "11          11    10.0  This is probably the best game I ever played. ...\n",
       "16          16    10.0  Fantastic game. Got me hooked on games all ove..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews= reviews.dropna()\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgW4k0gR78rP"
   },
   "source": [
    "### Reducing the number of classes for ratings\n",
    "\n",
    "I am using numpy round function to convert the double rating to corresponding integer values . This is will reduce the number of classes to 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "v3NY83RWh-qU",
    "outputId": "a8b4c4d3-9cee-48c2-e099-ab9ea0e7670e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0     657581\n",
      "7.0     574586\n",
      "6.0     526481\n",
      "9.0     239410\n",
      "5.0     217766\n",
      "10.0    153530\n",
      "4.0     136565\n",
      "3.0      70974\n",
      "2.0      40766\n",
      "1.0      20097\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "reviews['rating'] = np.around(reviews['rating'])\n",
    "reviews['rating'].replace(0.0,1.0, inplace=True)\n",
    "print(reviews['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "LTblfVxLtGve",
    "outputId": "2bc1ad7e-0193-4665-b59d-2ec7e740dda6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAdVUlEQVR4nO3df5QddZnn8feH3xGFgDB9YpKdZIYcnUgAoYEg6DbiQAAlzI4iDJrAZMg4IOCSGQ3Lrjgw7OIggmE0Y0YigUV+LMKSVSTmBK7gaICAgQCBkx4Ik2SBSAKBBgU7PPtHfXtz09y+XSFV9/a9/Xmdc09XPfXj+9wi3Q/fqm9VKSIwMzMr0g7NTsDMzNqPi4uZmRXOxcXMzArn4mJmZoVzcTEzs8Lt1OwEhop99tknxo0b1+w0tsvrr7/O7rvv3uw0hgQfi635eGzNx2OL7T0WDz/88EsRsW//uItLMm7cOJYtW9bsNLZLpVKhq6ur2WkMCT4WW/Px2JqPxxbbeywkPVcr7tNiZmZWOBcXMzMrnIuLmZkVzsXFzMwK5+JiZmaFc3ExM7PCubiYmVnhXFzMzKxwLi5mZlY436FvZkPOuNk/KXX/syb1csYAbay+/MRS2x4u3HMxM7PCubiYmVnhXFzMzKxwLi5mZlY4FxczMyuci4uZmRXOxcXMzArn4mJmZoVzcTEzs8K5uJiZWeFcXMzMrHAuLmZmVjgXFzMzK5yLi5mZFa7U4iJppKTbJD0laaWkIyTtLWmxpFXp515pXUmaI6lb0mOSDq7az/S0/ipJ06vih0hakbaZI0kpXrMNMzNrjLJ7Lt8G7o6IDwEHAiuB2cCSiJgALEnzAMcDE9JnJjAXskIBXAwcDhwGXFxVLOYCZ1VtNyXFB2rDzMwaoLTiImlP4OPAtQAR8VZEvAJMBRak1RYAJ6fpqcD1kVkKjJQ0CjgOWBwRGyPiZWAxMCUt2yMilkZEANf321etNszMrAHKfBPleOA3wA8kHQg8DJwPdETE82mdF4COND0aWFO1/doUqxdfWyNOnTa2ImkmWS+Jjo4OKpXKtn3DIaanp6flv0NRfCy21mrHY9ak3lL33zFi4DZa6TgVoax/G2UWl52Ag4FzI+IBSd+m3+mpiAhJUWIOdduIiHnAPIDOzs7o6uoqM5XSVSoVWv07FMXHYmutdjwGegVxUWZN6uXKFbX//K0+vavUtoeasv5tlHnNZS2wNiIeSPO3kRWbF9MpLdLP9Wn5OmBs1fZjUqxefEyNOHXaMDOzBiituETEC8AaSR9MoWOAJ4GFQN+Ir+nAnWl6ITAtjRqbDGxKp7YWAcdK2itdyD8WWJSWvSppcholNq3fvmq1YWZmDVDmaTGAc4EbJe0CPAOcSVbQbpU0A3gOOCWtexdwAtANvJHWJSI2SroUeCitd0lEbEzTZwPXASOAn6YPwOUDtGFmZg1QanGJiOVAZ41Fx9RYN4BzBtjPfGB+jfgyYP8a8Q212jAzs8bwHfpmZlY4FxczMytc2ddczKyFjSt5SLC1L/dczMyscC4uZmZWOBcXMzMrnIuLmZkVzsXFzMwK5+JiZmaFc3ExM7PCubiYmVnhXFzMzKxwLi5mZlY4FxczMyuci4uZmRXOxcXMzArn4mJmZoXzI/fNhrgiHns/a1IvZ/jx+dZA7rmYmVnhXFzMzKxwLi5mZlY4FxczMytcqcVF0mpJKyQtl7QsxfaWtFjSqvRzrxSXpDmSuiU9Jungqv1MT+uvkjS9Kn5I2n932lb12jAzs8ZoRM/l6Ig4KCI60/xsYElETACWpHmA44EJ6TMTmAtZoQAuBg4HDgMurioWc4GzqrabMkgbZmbWAM04LTYVWJCmFwAnV8Wvj8xSYKSkUcBxwOKI2BgRLwOLgSlp2R4RsTQiAri+375qtWFmZg1Q9n0uAfxMUgDfi4h5QEdEPJ+WvwB0pOnRwJqqbdemWL342hpx6rSxFUkzyXpJdHR0UKlUtvX7DSk9PT0t/x2K0k7HYtak3u3eR8eIYvbTLuodj3b5d5NXWb8rZReXoyJinaQ/ABZLeqp6YUREKjylqddGKnbzADo7O6Orq6vMVEpXqVRo9e9QlHY6FkXc/DhrUi9XrvA9033qHY/Vp3c1NpkmK+t3pdTTYhGxLv1cD9xBds3kxXRKi/RzfVp9HTC2avMxKVYvPqZGnDptmJlZA5RWXCTtLul9fdPAscDjwEKgb8TXdODONL0QmJZGjU0GNqVTW4uAYyXtlS7kHwssSstelTQ5jRKb1m9ftdowM7MGGLSfLOmPgbUR8aakLuAAsgvvrwyyaQdwRxodvBPww4i4W9JDwK2SZgDPAaek9e8CTgC6gTeAMwEiYqOkS4GH0nqXRMTGNH02cB0wAvhp+gBcPkAbZmbWAHlOwv4I6JS0H9n1iTuBH5IVggFFxDPAgTXiG4BjasQDOGeAfc0H5teILwP2z9uGmZk1Rp7TYm9HRC/wZ8A1EfF3wKhy0zIzs1aWp7j8XtJpZNcufpxiO5eXkpmZtbo8xeVM4Ajgsoh4VtJ44IZy0zIzs1aW55rLKOCrEfFbgIh4FvhGqVmZmVlLy9NzmQY8KmmppCskfdoPgjQzs3oG7blExHQASR8APgN8B/hAnm3NzGx4ynOfy+eBjwGTgJeAfwLuLzkvMzNrYXl6H1cD/wb8M3BvRKwuNSMzM2t5g15ziYh9gL8EdgMuk/SgJI8WMzOzAQ1aXCTtAfwH4A+BccCewNvlpmVmZq0sz2mxX1R9/iki1g6yvpmZDXN5RosdACDpPRHxRvkpmZlZq8tzWuwISU8CT6X5AyV9t/TMzMysZeW5ifJqsvfYbwCIiEeBj5eZlJmZtbZcLwuLiDX9QptLyMXMzNpEngv6ayR9FAhJOwPnAyvLTcvMzFpZnp7LF8le4jWa7B31BzHAS73MzMwg32ixl4DTG5CLmZm1iQGLi6SvRMQ/SroGiP7LI+K8UjMzM7OWVa/n0nddZVkjEjEzs/YxYHGJiP+TJldExCMNysfMzNpAngv6V0paKelSSfuXnpGZmbW8PE9FPho4GvgN8D1JKyT919IzMzOzlpX3JsoXImIO2bDk5cDX8jYgaUdJv5b04zQ/XtIDkrol3SJplxTfNc13p+XjqvZxYYo/Lem4qviUFOuWNLsqXrMNMzNrjDzPFvsTSV+X9DhwDfBLYMw2tNH/pstvAFdFxH7Ay8CMFJ8BvJziV6X1kDQROBX4MDAF+G4qWDuSvXL5eGAicFpat14bZmbWAHl6LvPJ/kAfGxFdETE3Itbn2bmkMcCJwPfTvIBPALelVRYAJ6fpqWmetPyYtP5U4OaIeDMingW6gcPSpzsinomIt4CbgamDtGFmZg2Q5ybKIySNIHth2La6GvgK8L40/37glYjoTfNrye78J/1ck9rslbQprT8aWFq1z+pt1vSLHz5IG1uRNBOYCdDR0UGlUtn2bziE9PT0tPx3KEo7HYtZk3oHX2kQHSOK2U+7qHc82uXfTV5l/a4MWlwkfRr4JrALMF7SQcAlEXHSINt9ClgfEQ9L6ioi2aJFxDxgHkBnZ2d0dXU1N6HtVKlUaPXvUJR2OhZnzP7Jdu9j1qRerlyR51GCw0O947H69K7GJtNkZf2u5PnX9nWyU1AVgIhYLml8ju2OBE6SdAKwG7AH8G1gpKSdUs9iDNnzykg/xwJrJe1E9jrlDVXxPtXb1IpvqNOGmZk1QJ5rLr+PiE39Yu94HEx/EXFhRIyJiHFkF+TviYjTgXuBz6TVpgN3pumFaZ60/J6IiBQ/NY0mGw9MAB4EHgImpJFhu6Q2FqZtBmrDzMwaIE9xeULSXwA7SpqQnjX2y+1o86vABZK6ya6PXJvi1wLvT/ELgNkAEfEEcCvwJHA3cE5EbE69ki8Bi8hGo92a1q3XhpmZNUCe02LnAhcBbwI/JPtj/g/b0khEVNhyWu0ZstNs/df5HfDZAba/DLisRvwu4K4a8ZptmJlZY9QtLulekp+ku/QvakxKZmbW6uqeFouIzcDbkvZsUD5mZtYG8pwW6wFWSFoMvN4X9PtczMxsIHmKy+3pY2ZmlkueO/QXDLaOmZlZtVxPRTYzM9sWLi5mZla4AYuLpBvSz/Mbl46ZmbWDej2XQyR9APhLSXtJ2rv606gEzcys9dS7oP/PwBLgj4CHAVUtixQ3MzN7hwF7LhExJyL+BJgfEX8UEeOrPi4sZmY2oDxDkf9G0oHAx1Lovoh4rNy0zMyslQ06WkzSecCNwB+kz42Szi07MTMza1157tD/K+DwiHgdQNI3gF8B15SZmJmZta4897kI2Fw1v5mtL+6bmZltJU/P5QfAA5LuSPMn45dvmZlZHXku6H9LUgU4KoXOjIhfl5qVmZm1tDw9FyLiEeCRknMxM7M24WeLmZlZ4VxczMyscHWLi6QdJd3bqGTMzKw91C0uEbEZeFvSng3Kx8zM2kCe02I9wApJ10qa0/cZbCNJu0l6UNKjkp6Q9PcpPl7SA5K6Jd0iaZcU3zXNd6fl46r2dWGKPy3puKr4lBTrljS7Kl6zDTMza4w8xeV24L8B95E9HbnvM5g3gU9ExIHAQcAUSZOBbwBXRcR+wMvAjLT+DODlFL8qrYekicCpwIeBKcB30+m6HYHvAMcDE4HT0rrUacPMzBpg0OISEQuAW4GlEbGg75Nju4iInjS7c/oE8AngthRfQHZTJsDUNE9afowkpfjNEfFmRDwLdAOHpU93RDwTEW8BNwNT0zYDtWFmZg0w6H0ukj4NfBPYBRgv6SDgkog4Kce2O5L1cvYj62X8G/BKRPSmVdYCo9P0aGANQET0StoEvD/Fl1bttnqbNf3ih6dtBmqjf34zgZkAHR0dVCqVwb7SkNbT09Py36Eo7XQsZk3qHXylQXSMKGY/7aLe8WiXfzd5lfW7kucmyq+T9RIqABGxXFKu97mkAQEHSRoJ3AF86N2lWY6ImAfMA+js7Iyurq7mJrSdKpUKrf4ditJOx+KM2T/Z7n3MmtTLlSty3TM9LNQ7HqtP72psMk1W1u9Knmsuv4+ITf1ib29LIxHxCnAvcAQwUlLff9UxwLo0vQ4YC5CW7wlsqI7322ag+IY6bZiZWQPkKS5PSPoLYEdJEyRdA/xysI0k7Zt6LEgaAfwpsJKsyHwmrTYduDNNL0zzpOX3RESk+KlpNNl4YALwIPAQMCGNDNuF7KL/wrTNQG2YmVkD5Cku55KN1HoTuAl4Ffhyju1GAfdKeoysECyOiB8DXwUukNRNdn2k7wnL1wLvT/ELgNkAEfEE2YCCJ4G7gXMiYnO6pvIlYBFZ0bo1rUudNszMrAHyPBX5DeCi9JKwiIjX8uw4vQr5IzXiz5Bdw+kf/x3w2QH2dRlwWY34XcBdedswM7PGyPOa40MlrQAeI7uZ8lFJh5SfmpmZtao8w0euBc6OiPsBJB1F9gKxA8pMzMzMWleeay6b+woLQET8AvCAeTMzG9CAPRdJB6fJn0v6HtnF/AA+R7rnxczMrJZ6p8Wu7Dd/cdV0lJCLmZm1iQGLS0Qc3chEzMysfeR5tthIYBowrnr9iDivvLTMzKyV5RktdhfZgyNXsI2PfTEzs+EpT3HZLSIuKD0TMzNrG3mGIt8g6SxJoyTt3fcpPTMzM2tZeXoubwFXABexZZRYALkeu29mZsNPnuIyC9gvIl4qOxkzM2sPeU6LdQNvlJ2ImZm1jzw9l9eB5ZLuJXvsPuChyGbWnsYV8ObPd2P15Sc2pd2y5Cku/zt9zMzMcsnzPpcFjUjEzMzaR5479J+lxrPEIsKjxczMrKY8p8U6q6Z3I3tbpO9zMTOzAQ06WiwiNlR91kXE1UB7XXkyM7NC5TktdnDV7A5kPZk8PR4zMxum8hSJ6ve69AKrgVNKycZsCGvWEFWzVpRntJjf62JmZtskz2mxXYE/553vc7mkvLTMzKyV5Xn8y53AVLJTYq9XfeqSNFbSvZKelPSEpPNTfG9JiyWtSj/3SnFJmiOpW9Jj1dd6JE1P66+SNL0qfoikFWmbOZJUrw0zM2uMPMVlTER8LiL+MSKu7Pvk2K4XmBURE4HJwDmSJgKzgSURMQFYkuYBjgcmpM9MYC5khQK4GDgcOAy4uKpYzAXOqtpuSooP1IaZmTVAnuLyS0mTtnXHEfF8RDySpl8DVgKjyXpBfXf9LwBOTtNTgesjsxQYKWkUcBywOCI2RsTLwGJgSlq2R0QsjYgAru+3r1ptmJlZA+QZLXYUcEa6U/9NQEBExAF5G5E0DvgI8ADQERHPp0UvAB1pejSwpmqztSlWL762Rpw6bfTPayZZL4mOjg4qlUrerzQk9fT0tPx3KEoZx2LWpN5C99dIHSNaO/+iDcXj0azf3bL+buQpLsdvTwOS3gv8CPhyRLyaLosAWYWS9I5HyxSpXhsRMQ+YB9DZ2RldXV1lplK6SqVCq3+HopRxLM5o4aHIsyb1cuUK357WZygej9WndzWl3bL+buQZivzcu925pJ3JCsuNEXF7Cr8oaVREPJ9Oba1P8XXA2KrNx6TYOqCrX7yS4mNqrF+vDTMza4A811zelTRy61pgZUR8q2rRQqBvxNd0stFoffFpadTYZGBTOrW1CDhW0l7pQv6xwKK07FVJk1Nb0/rtq1YbZmbWAGX2C48EvgCskLQ8xf4LcDlwq6QZwHNsudv/LuAEtrz58kyAiNgo6VLgobTeJRGxMU2fDVwHjAB+mj7UacPMzBqgtOISEb8gu/hfyzE11g/gnAH2NR+YXyO+DNi/RnxDrTbMzKwxSjstZmZmw5eLi5mZFc7FxczMCufiYmZmhXNxMTOzwrm4mJlZ4VxczMyscC4uZmZWuKH15DYzs2FqXJMejHrdlN1L2a97LmZmVjgXFzMzK5yLi5mZFc7FxczMCufiYmZmhfNoMWspeUfUzJrU29KvJTZrde65mJlZ4VxczMyscC4uZmZWOBcXMzMrnIuLmZkVzsXFzMwK5+JiZmaFK624SJovab2kx6tie0taLGlV+rlXikvSHEndkh6TdHDVNtPT+qskTa+KHyJpRdpmjiTVa8PMzBqnzJ7LdcCUfrHZwJKImAAsSfMAxwMT0mcmMBeyQgFcDBwOHAZcXFUs5gJnVW03ZZA2zMysQUorLhFxH7CxX3gqsCBNLwBOropfH5mlwEhJo4DjgMURsTEiXgYWA1PSsj0iYmlEBHB9v33VasPMzBqk0Y9/6YiI59P0C0BHmh4NrKlab22K1YuvrRGv18Y7SJpJ1lOio6ODSqWyjV9naOnp6Wn57zCYWZN6c63XMSL/usOBj8fWfDy2KOvvRtOeLRYRISma2UZEzAPmAXR2dkZXV1eZ6ZSuUqnQ6t9hMHmfFzZrUi9XrvCj8/r4eGzNx2OL66bsXsrfjUaPFnsxndIi/Vyf4uuAsVXrjUmxevExNeL12jAzswZpdHFZCPSN+JoO3FkVn5ZGjU0GNqVTW4uAYyXtlS7kHwssSstelTQ5jRKb1m9ftdowM7MGKa1fKOkmoAvYR9JaslFflwO3SpoBPAeckla/CzgB6AbeAM4EiIiNki4FHkrrXRIRfYMEziYbkTYC+Gn6UKcNMzNrkNKKS0ScNsCiY2qsG8A5A+xnPjC/RnwZsH+N+IZabZiZWeP4Dn0zMyuci4uZmRXOxcXMzArngd72ruR9l72ZDU/uuZiZWeFcXMzMrHAuLmZmVjgXFzMzK5yLi5mZFc7FxczMCufiYmZmhXNxMTOzwrm4mJlZ4XyHfgvrf5f8rEm9ud/UaGZWJvdczMyscC4uZmZWOBcXMzMrnIuLmZkVzsXFzMwK59FiBfC7TczMtuaei5mZFc7FxczMCufiYmZmhWvb4iJpiqSnJXVLmt3sfMzMhpO2LC6SdgS+AxwPTAROkzSxuVmZmQ0fbVlcgMOA7oh4JiLeAm4GpjY5JzOzYUMR0ewcCifpM8CUiPirNP8F4PCI+FK/9WYCM9PsB4GnG5po8fYBXmp2EkOEj8XWfDy25uOxxfYeiz+MiH37B4f1fS4RMQ+Y1+w8iiJpWUR0NjuPocDHYms+Hlvz8diirGPRrqfF1gFjq+bHpJiZmTVAuxaXh4AJksZL2gU4FVjY5JzMzIaNtjwtFhG9kr4ELAJ2BOZHxBNNTqsR2uYUXwF8LLbm47E1H48tSjkWbXlB38zMmqtdT4uZmVkTubiYmVnhXFxanKSxku6V9KSkJySd3+ychgJJO0r6taQfNzuXZpM0UtJtkp6StFLSEc3OqVkk/ef0e/K4pJsk7dbsnBpJ0nxJ6yU9XhXbW9JiSavSz72KaMvFpfX1ArMiYiIwGTjHj7oB4HxgZbOTGCK+DdwdER8CDmSYHhdJo4HzgM6I2J9ssM+pzc2q4a4DpvSLzQaWRMQEYEma324uLi0uIp6PiEfS9GtkfzhGNzer5pI0BjgR+H6zc2k2SXsCHweuBYiItyLileZm1VQ7ASMk7QS8B/i/Tc6noSLiPmBjv/BUYEGaXgCcXERbLi5tRNI44CPAA83NpOmuBr4CvN3sRIaA8cBvgB+k04Tfl7R7s5NqhohYB3wT+HfgeWBTRPysuVkNCR0R8XyafgHoKGKnLi5tQtJ7gR8BX46IV5udT7NI+hSwPiIebnYuQ8ROwMHA3Ij4CPA6BZ32aDXpWsJUsoL7AWB3SZ9vblZDS2T3phRyf4qLSxuQtDNZYbkxIm5vdj5NdiRwkqTVZE/D/oSk/9nclJpqLbA2Ivp6s7eRFZvh6JPAsxHxm4j4PXA78NEm5zQUvChpFED6ub6Inbq4tDhJIjufvjIivtXsfJotIi6MiDERMY7sYu09ETFs/+80Il4A1kj6YAodAzzZxJSa6d+ByZLek35vjmGYDm7oZyEwPU1PB+4sYqcuLq3vSOALZP+Hvjx9Tmh2UjaknAvcKOkx4CDgvzc5n6ZIvbfbgEeAFWR//4bVY2Ak3QT8CvigpLWSZgCXA38qaRVZ7+7yQtry41/MzKxo7rmYmVnhXFzMzKxwLi5mZlY4FxczMyuci4uZmRXOxcVsG0n6sqT3VM3fJWlkyW1ekZ7me0XB+/2ipGlF7tMMPBTZ7B3SDXaKiJrPJkt3/3dGxEsNzGkTsHdEbK6zzk4R0duonMzqcc/FjOyhn5KelnQ98DgwVtJcSctSj+Hv03rnkT2X6l5J96bYakn7pH2slPQvaZufSRqR1jlU0mPpJtcrqt+nUZWD+pZJWiHpcym+EHgv8HBfrGqbr0u6QdK/AjdI2lfSjyQ9lD5HStoh5TiyartVkjrS9n+bYn8s6W5JD0u6X9KH0ntxnk25jZS0WdLH0/r3SZpQ+H8MawsuLmZbTAC+GxEfjojngIsiohM4APiPkg6IiDlkj2k/OiKOHmAf34mIDwOvAH+e4j8A/joiDgIG6n38J7I76A8ku1P6CkmjIuIk4LcRcVBE3FJju4nAJyPiNLJ3t1wVEYemtr+femB3An8GIOlw4LmIeLHffuYB50bEIcDfpmOxGXg6tXEU2d3tH5O0KzA2IlYN8F1smNup2QmYDSHPRcTSqvlTJM0k+z0ZRfYH9rFB9vFsRCxP0w8D41KP4X0R8asU/yHwqRrbHgXclP6gvyjp58ChZM9+qmdhRPw2TX8SmJid2QNgj/TE7FuAr5EVuVPT/P+X1vko8L+qtt01/byf7J0w44H/AZwF/Bx4aJC8bBhzcTHb4vW+CUnjyf7v/dCIeFnSdUCeV+K+WTW9GRhRaIa1vV41vQMwOSJ+V72CpF8B+0nal+xlUP/Qbx87AK+knlV/9wF/Q3Y68GvA3wFdZEXHrCafFjOrbQ+yP9qbJHUAx1ctew14X94dpTc/vpZOR8HAr9a9H/hcus6xL1lv4cFtzPtnZA+qBEDSQSmHAO4AvkX2BO0N/XJ8FXhW0mfTdpJ0YFr8IFmv5u1UtJYDf01WdMxqcnExqyEiHgV+DTxFdhrrX6sWzwPu7rugn9MM4F8kLQd2BzbVWOcOstNujwL3AF9Jj8zfFucBnWnwwJPAF6uW3QJ8nn6nxKqcDsyQ9CjwBNmLtYiIN4E1QN8pw/vJiuuKbczNhhEPRTZrAEnvjYieND0bGBUR5zc5LbPS+JqLWWOcKOlCst+554AzmpuOWbncczEzs8L5mouZmRXOxcXMzArn4mJmZoVzcTEzs8K5uJiZWeH+H2h47bS1notlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews.head()\n",
    "reviews['rating'].hist(bins=10)\n",
    "plt.xlabel('rating of review')\n",
    "plt.ylabel('number of reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3_22UvU78rX"
   },
   "source": [
    "### Balancing the data\n",
    "\n",
    "The data is still unbalanced as we can see that we have more data for rating of 7 and 8 . So to feed the neural network we need to balance the data . I am using pandas to extract frames of individual ratings from the data and then sampling them to a single value so that all the ratings have equal number of data. Finally I use concatenate to add all data into a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HsB6s17qURnc"
   },
   "outputs": [],
   "source": [
    "sam = 20000\n",
    "\n",
    "reviews_rate_1 = reviews[reviews['rating']  == 1.0]\n",
    "reviews_rate_2 = reviews[reviews['rating']  == 2.0]\n",
    "reviews_rate_3 = reviews[reviews['rating']  == 3.0]\n",
    "reviews_rate_4 = reviews[reviews['rating']  == 4.0]\n",
    "reviews_rate_5 = reviews[reviews['rating']  == 5.0]\n",
    "reviews_rate_6 = reviews[reviews['rating']  == 6.0]\n",
    "reviews_rate_7 = reviews[reviews['rating']  == 7.0]\n",
    "reviews_rate_8 = reviews[reviews['rating']  == 8.0]\n",
    "reviews_rate_9 = reviews[reviews['rating']  == 9.0]\n",
    "reviews_rate_10 = reviews[reviews['rating']  == 10.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHnoEODBWNSz"
   },
   "outputs": [],
   "source": [
    "\n",
    "reviews_rate_1 = reviews_rate_1.sample(sam)\n",
    "reviews_rate_2 = reviews_rate_2.sample(sam)\n",
    "reviews_rate_3 = reviews_rate_3.sample(sam)\n",
    "reviews_rate_4 = reviews_rate_4.sample(sam)\n",
    "reviews_rate_5 = reviews_rate_5.sample(sam)\n",
    "reviews_rate_6 = reviews_rate_6.sample(sam)\n",
    "reviews_rate_7 = reviews_rate_7.sample(sam)\n",
    "reviews_rate_8 = reviews_rate_8.sample(sam)\n",
    "reviews_rate_9 = reviews_rate_9.sample(sam)\n",
    "reviews_rate_10 = reviews_rate_10.sample(sam)\n",
    "reviews_balanced = pd.concat([reviews_rate_1,reviews_rate_2,reviews_rate_3,\n",
    "                              reviews_rate_4,reviews_rate_5,reviews_rate_6,reviews_rate_7,\n",
    "                              reviews_rate_8,reviews_rate_9,reviews_rate_10],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "x8XHL_wqW3Ve",
    "outputId": "29281957-d7c5-46a9-b47a-a6a0ebcf1548"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13074175</th>\n",
       "      <td>13074175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is not a game.  This is not a toy.  It is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596409</th>\n",
       "      <td>11596409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not very interesting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410177</th>\n",
       "      <td>6410177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Awful game, bad balancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040006</th>\n",
       "      <td>13040006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This is an old Hungarian version of Monopoly t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662505</th>\n",
       "      <td>12662505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Truly awful game, I can't imagine what Avalon ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  rating                                            comment\n",
       "13074175    13074175     1.0  This is not a game.  This is not a toy.  It is...\n",
       "11596409    11596409     1.0                              Not very interesting.\n",
       "6410177      6410177     1.0                          Awful game, bad balancing\n",
       "13040006    13040006     1.0  This is an old Hungarian version of Monopoly t...\n",
       "12662505    12662505     1.0  Truly awful game, I can't imagine what Avalon ..."
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JEAnFtn1iFba",
    "outputId": "826f215d-c105-40ed-d1a0-2fba40e99cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0     20000\n",
      "8.0     20000\n",
      "5.0     20000\n",
      "6.0     20000\n",
      "4.0     20000\n",
      "9.0     20000\n",
      "3.0     20000\n",
      "10.0    20000\n",
      "2.0     20000\n",
      "1.0     20000\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(reviews_balanced['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHYoAZwo9jzU"
   },
   "source": [
    "### Cleaning the data\n",
    "\n",
    "This is one of the more important past of text preprocessing . Since everybody has a different writing style we need to make sure that data is error free and consistent. The first things is make sure that the data is lowercase so that our model doesnot consider 'Hello' and 'hello' as two different features. Then we use NLTK library to download all the english stopwords and remove them from my data. Stopwords include is , the etc which have know meaning in determining the rating of the review so we remove them. Finally , we clean all the contractions , punctutions and abbreviations from the data using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TF4ViQ6ji0hM"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNdeI11rvdA1"
   },
   "outputs": [],
   "source": [
    "reviews_balanced['comment'] = reviews_balanced['comment'].map(lambda text : clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Cmi2YEHM78r-",
    "outputId": "1036ad60-d7c2-4d9f-8d93-d47e2f4800aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13074175</th>\n",
       "      <td>13074175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>game toy inconceivable anyone thought could se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596409</th>\n",
       "      <td>11596409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>interesting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410177</th>\n",
       "      <td>6410177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>awful game bad balancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040006</th>\n",
       "      <td>13040006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>old hungarian version monopoly board streets b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662505</th>\n",
       "      <td>12662505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>truly awful game ca not imagine avalon hill th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  rating                                            comment\n",
       "13074175    13074175     1.0  game toy inconceivable anyone thought could se...\n",
       "11596409    11596409     1.0                                       interesting \n",
       "6410177      6410177     1.0                           awful game bad balancing\n",
       "13040006    13040006     1.0  old hungarian version monopoly board streets b...\n",
       "12662505    12662505     1.0  truly awful game ca not imagine avalon hill th..."
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArTE9Sho78sC"
   },
   "source": [
    "## Data Preprocessing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbWUOB2E78sC"
   },
   "source": [
    "### Review length \n",
    "\n",
    "First we need to find out what is the length of reviews in our data set . This is important beacause we need to tokenize our data and we need to define certain hyperparameters for our model. This will all be possible and more optimised if we fully understand the data. I am using pandas to calculate the number of words for each comment , then we create 5 word bins based on the number of words each of these comments have. Finally I display the number of comments we have in each of the bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PvKQfTB0o0Sx"
   },
   "outputs": [],
   "source": [
    "reviews_balanced['num_words'] = reviews_balanced.comment.apply(lambda x : len(x.split()))\n",
    "reviews_balanced['bins']=pd.cut(reviews_balanced.num_words, bins=[0,100,300,500,800, np.inf], labels=['0-100', '100-300', '300-500','500-800' ,'>800'])\n",
    "word_distribution = reviews_balanced.groupby('bins').size().reset_index().rename(columns={0:'counts'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sAlGKivspwQC",
    "outputId": "beb8799c-c263-4cc8-c7c0-1fe3815641e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bins</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-100</td>\n",
       "      <td>191519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100-300</td>\n",
       "      <td>5319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300-500</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500-800</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt;800</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      bins  counts\n",
       "0    0-100  191519\n",
       "1  100-300    5319\n",
       "2  300-500     368\n",
       "3  500-800      81\n",
       "4     >800      27"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_distribution.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-s7QxEf78sR"
   },
   "source": [
    "We can see that majority of our comments have a word count between 0-100 . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "StkygLs978sR"
   },
   "source": [
    "### Dividing the data\n",
    "\n",
    "We need to divide the data into testing and training data. For this I am using train_test_split() function by sklearn . This divides the data randomly by into the ratio provided by the user as a paramter. Here i haves used '0.3' , So I got a 70:30 ratio of train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHa6RXXBXVIY"
   },
   "outputs": [],
   "source": [
    "x_train ,x_test, y_train, y_test = train_test_split(reviews_balanced.comment, reviews_balanced['rating'], test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "8HXdnSZujaSM",
    "outputId": "a2483765-07d9-4de1-96e0-cdf85dd1011d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,)\n",
      "(60000,)\n",
      "(140000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29Ozqu1F78sZ"
   },
   "source": [
    "### Tokenization and BOW Vocabulary\n",
    "\n",
    "Before the data can be fed into neural network model , we need to make tokenize the data . Tokenization is the process of converting the data into numbers , since a computer can only understand numbers. Tokenization works by creating a dictionary of the most used words in a sentence then replacing the word by its corresponding index.\n",
    "\n",
    "Suppose we have : \n",
    "\n",
    "\"Hello this is rohan \" - THIS IS NOT UNDERSTANDABLE BY A MACHINE\n",
    "\n",
    "We tokenize it by creating a dictionary : \n",
    "\n",
    "{ Hello : 1 , this : 2 , is : 3 , Rohan : 4 }\n",
    "\n",
    "Then we replace the word by its corresponding index. So now our sentence becomes : \n",
    "\n",
    "[1 , 2, 3, 4] - THIS IS UNDERSTANDABLE BY A MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KH2ZKCBOCcp7"
   },
   "outputs": [],
   "source": [
    "max_features = 10000\n",
    "tokenizer = Tokenizer(num_words=max_features,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower = True,oov_token='OOV')\n",
    "tokenizer.fit_on_texts([list(x_train),list(x_test)])\n",
    "x_train_1 = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_1 = tokenizer.texts_to_sequences(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5iTaQa578sk"
   },
   "source": [
    "I used keras tokenizer() function to create a BOW . I haves specified max_features which will extract top 10000 words from the corpus. Filters argument will not consider all the symbols as features , since they have no significanc over the ratings and oov_token is used to represent out of vocabulary words.Then I am using both test and train data to create this BOW using fit_on_texts() function. Finally I am converting the the sentences to machine readable vectors using text_to_sequences() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKpcOtLYCcqB"
   },
   "outputs": [],
   "source": [
    "### Padding and Tensors\n",
    "\n",
    "Since we are using tensorflow we need to create the input tensors . This is very simple but we know that the length of our text sequences are different. A NN takes in input of the input size provided during model compilation , so we need to make sure that all of our tensors are of equal length. \n",
    "\n",
    "This is were we use padding. Padding means adding zeros either at the begining or at the end of the text sequences. The number of zeroes depend upon the how many zeros are need to make all the sequence of equal length. I am using keras pad_sequences function. We need to specifiy the maximum length of the sequence . As we know most of our data is < 100 words I am using max_len of 100. To save training time and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3KFHUMrCcqD"
   },
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "x_train_1 = pad_sequences(x_train_1,max_len, padding = \"post\")\n",
    "x_test_1 = pad_sequences(x_test_1,max_len, padding = \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "OZekEpv3laRy",
    "outputId": "1318fbc2-88ff-4c81-a58a-f08192640c66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[614   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54D-v3QA78tC"
   },
   "source": [
    "The result of padding gives a tensor of 100 length.The zeros were added in the end since i specified padding as 'Post'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFowBNtV78tD"
   },
   "source": [
    "### Vocabulary\n",
    "\n",
    "The tokenizer function creates a dictionary of words which is our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qqLDE3Fp78tK",
    "outputId": "570ada63-cee3-472d-ab26-cd34bb514c48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OOV': 1,\n",
       " '': 2,\n",
       " ' ': 3,\n",
       " 'kickstarter': 4,\n",
       " 'played': 5,\n",
       " 'players': 6,\n",
       " 'game ': 7,\n",
       " 'meh ': 8,\n",
       " 'kids': 9,\n",
       " 'boring ': 10,\n",
       " 'sleeved': 11,\n",
       " 'pnp': 12,\n",
       " 'sold': 13,\n",
       " 'game': 14,\n",
       " 'smjj loves game therefore hate': 15,\n",
       " 'meh': 16,\n",
       " 'boring': 17,\n",
       " 'reviewed blog ': 18,\n",
       " '2 - 4': 19,\n",
       " 'plays': 20,\n",
       " 'play': 21,\n",
       " 'i am interested type experience via board game medium consider board game ': 22,\n",
       " '2 - 4 players': 23,\n",
       " ' : thumbsdown : communcal cards : thumbsdown : strategically shallow : thumbsdown : tediously tactical': 24,\n",
       " 'ios': 25,\n",
       " 'kickstarted': 26,\n",
       " 'great game': 27,\n",
       " 'fun': 28,\n",
       " 'good game': 29,\n",
       " 'sell': 30,\n",
       " ' url = http : fortressat com articles - analysis 2767 - idiots i play url ': 31,\n",
       " 'p p': 32,\n",
       " 'best': 33,\n",
       " 'need try': 34,\n",
       " '2 - 5': 35,\n",
       " 'classic': 36,\n",
       " ' ! ': 37,\n",
       " 'brazil brazilian publisher redbox positioned conservative candidate may contribute communist candidate winning elections ': 38,\n",
       " 'no ': 39,\n",
       " 'good game ': 40,\n",
       " 'see www brettspillguiden no norwegian only sorry ! ': 41,\n",
       " 'app': 42,\n",
       " 'player': 43,\n",
       " 'played once ': 44,\n",
       " 'ugh ': 45,\n",
       " '2 - 5 players': 46,\n",
       " 'plays : ': 47,\n",
       " 'storage': 48,\n",
       " 'classic ': 49,\n",
       " 'fun ': 50,\n",
       " 'comments': 51,\n",
       " 'great game ': 52,\n",
       " 'yawn ': 53,\n",
       " 'comment rate later ! ': 54,\n",
       " 'kickstarter edition': 55,\n",
       " 'came here people rating games like kd : m hate mature theme i m offended boring theme game is ! ': 56,\n",
       " 'game collectible means gameplay fundamentally broken process figuring combinations better puzzle game sitting constructing deck definition solitary play puzzle beyond business model collectible games deplorable form gambling targeted towards children adds benefit gameplay done specifically milk much money people possible ': 57,\n",
       " 'love game': 58,\n",
       " 'sell trade locally': 59,\n",
       " 'great game ! ': 60,\n",
       " 'traded': 61,\n",
       " 'solo': 62,\n",
       " 'worst game ever ': 63,\n",
       " 'love game ! ': 64,\n",
       " 'fun : quality : - not game - 5 ': 65,\n",
       " 'kids game': 66,\n",
       " 'cup tea ': 67,\n",
       " 'card': 68,\n",
       " 'unplayed': 69,\n",
       " 'love game ': 70,\n",
       " 'enfundado': 71,\n",
       " 'good': 72,\n",
       " 'given away': 73,\n",
       " 'love it ! ': 74,\n",
       " 'never again ': 75,\n",
       " 'terrible ': 76,\n",
       " 'like new': 77,\n",
       " '3 - 6 players': 78,\n",
       " 'kind game ': 79,\n",
       " 'nis': 80,\n",
       " 'digital': 81,\n",
       " '2 - 6 players': 82,\n",
       " 'comments ': 83,\n",
       " 'broken ': 84,\n",
       " 'nothing wrong game i am sure splendid affair however watching run reading reviews absolutely desire play ': 85,\n",
       " 'awful ': 86,\n",
       " 'good ': 87,\n",
       " 'type game ': 88,\n",
       " 'hate game ': 89,\n",
       " 'play one time': 90,\n",
       " 'keep': 91,\n",
       " '2 - 6': 92,\n",
       " 'rated expansion appear searching unplayed games': 93,\n",
       " '0 - 1': 94,\n",
       " 'backed kickstarter': 95,\n",
       " 'party game': 96,\n",
       " ' 1 19 ': 97,\n",
       " 'love': 98,\n",
       " 'me ': 99,\n",
       " 'homemade': 100,\n",
       " 'broken': 101,\n",
       " 'family': 102,\n",
       " '2018': 103,\n",
       " 'sale': 104,\n",
       " 'new shrink': 105,\n",
       " ' url = http : hyperboleandahalf blogspot com 2010 02 please - stop html please stop url ': 106,\n",
       " 'played times': 107,\n",
       " 'copies': 108,\n",
       " 'box': 109,\n",
       " 'expansions': 110,\n",
       " 'really game ': 111,\n",
       " 'complete': 112,\n",
       " 'fun game ': 113,\n",
       " 'why ': 114,\n",
       " 'bad': 115,\n",
       " 'like trivia games certain categories information almost zero knowledge less zero interest know answer also want know answer ever played specific version trivial pursuit; however rating accurately reflects desire play it ': 116,\n",
       " 'excellent game ': 117,\n",
       " 'print play': 118,\n",
       " 'kickstarter ! ': 119,\n",
       " 'version': 120,\n",
       " 'reason rating http : www boardgamegeek com geeklist 48933': 121,\n",
       " 'expansion': 122,\n",
       " 'even game ': 123,\n",
       " 'gift': 124,\n",
       " 'sold geekway 2017': 125,\n",
       " 'gosto sentir experi ncia consumismo respons vel enquanto jogo seja jogos que jogarei dezenas vezes e ou que depois ainda posso vender trocar doar ': 126,\n",
       " 'like it ': 127,\n",
       " 'thrift store find ! ': 128,\n",
       " 'donated': 129,\n",
       " 'sale ': 130,\n",
       " 'rules spanish': 131,\n",
       " 'basement': 132,\n",
       " 'ipad': 133,\n",
       " 'bad ': 134,\n",
       " 'party game ': 135,\n",
       " 'compleet': 136,\n",
       " 'work well 2p ': 137,\n",
       " 'co - op': 138,\n",
       " 'execrable product': 139,\n",
       " 'eh ': 140,\n",
       " 'fun ! ': 141,\n",
       " '3 - 4': 142,\n",
       " 'like': 143,\n",
       " 'best game ever ': 144,\n",
       " 'ios version': 145,\n",
       " 'stupid': 146,\n",
       " 'played : ': 147,\n",
       " 'bermuda': 148,\n",
       " ' - ': 149,\n",
       " 'awesome ! ': 150,\n",
       " 'great': 151,\n",
       " 'fun party game ': 152,\n",
       " 'cards': 153,\n",
       " 'rental : 20': 154,\n",
       " 'couderches': 155,\n",
       " 'home': 156,\n",
       " 'amazon': 157,\n",
       " 'kids ': 158,\n",
       " 'monopoly ': 159,\n",
       " 'easy': 160,\n",
       " '2019': 161,\n",
       " 'keeper': 162,\n",
       " 'worker placement game terrible': 163,\n",
       " 'excellent game': 164,\n",
       " 'ugh': 165,\n",
       " 'boite': 166,\n",
       " 'played less times': 167,\n",
       " 'activity game ': 168,\n",
       " 'fun : quality : - no influence - 5 ': 169,\n",
       " 'best game ever': 170,\n",
       " 'kickstarted ': 171,\n",
       " 'top': 172,\n",
       " 'yuck ': 173,\n",
       " 'spsu': 174,\n",
       " 'worst game ever played ': 175,\n",
       " 'unfortunately 26 - 11 - 2009 bgg instructed remove uploaded files games even files copyrite material games might company attitude customers definitely broken game ratings reduced 1 mend piss poor attitude client base files allowed reinstated ': 176,\n",
       " 'crap': 177,\n",
       " 'long ': 178,\n",
       " 'gateway': 179,\n",
       " ' t ': 180,\n",
       " 'best players ': 181,\n",
       " 'kind game': 182,\n",
       " 'solved ': 183,\n",
       " 'pointless ': 184,\n",
       " 'preliminary rating one play ': 185,\n",
       " '10 ': 186,\n",
       " 'deluxe edition': 187,\n",
       " 'long': 188,\n",
       " 'decisions game ': 189,\n",
       " 'yawn': 190,\n",
       " 'disgusting policy': 191,\n",
       " 'awesome game': 192,\n",
       " 'edition': 193,\n",
       " 'thing ': 194,\n",
       " 'fun : quality : - little influence - 3 - few options - 1 ': 195,\n",
       " 'awful': 196,\n",
       " 'coop': 197,\n",
       " 'jugadores': 198,\n",
       " 'stupid ': 199,\n",
       " 'nice game': 200,\n",
       " 'essen 2014': 201,\n",
       " 'essen': 202,\n",
       " 'it ': 203,\n",
       " 'scam': 204,\n",
       " 'awesome game ! ': 205,\n",
       " 'see review ': 206,\n",
       " 'like new played once ': 207,\n",
       " 'decisions game': 208,\n",
       " 'crap ': 209,\n",
       " 'family game': 210,\n",
       " 'would pay play game : ': 211,\n",
       " 'lol': 212,\n",
       " 'good condition': 213,\n",
       " 'terrible': 214,\n",
       " '2er': 215,\n",
       " 'kids game ': 216,\n",
       " 'bad ass ': 217,\n",
       " 'random ': 218,\n",
       " 'played yet ': 219,\n",
       " 'came here people rating mature themed games like kd : m hate mature theme games theme boring ! ': 220,\n",
       " 'classic game': 221,\n",
       " 'issue game publisher policy like destination policy leads to leads flooding bad games good games substandard production reaching higher prices consumer object scenario hence rating ': 222,\n",
       " 'another gameid = 1406 clone ': 223,\n",
       " 'card game': 224,\n",
       " 'best game ever ! ': 225,\n",
       " 'fun filler ': 226,\n",
       " 'excellent ! ': 227,\n",
       " 'essen 2010': 228,\n",
       " 'trade ': 229,\n",
       " 'excellent': 230,\n",
       " 'traded away ': 231,\n",
       " '2nd edition': 232,\n",
       " ' url = https : i giphy com media oazk0wnso7fxi giphy webp please stop url ': 233,\n",
       " 'good kids ': 234,\n",
       " 'dull ': 235,\n",
       " ' basegame': 236,\n",
       " 'overhyped nonsense ': 237,\n",
       " 'children game': 238,\n",
       " 'seth owns ': 239,\n",
       " 'awesome': 240,\n",
       " 'sleeved ': 241,\n",
       " ' ksp': 242,\n",
       " 'solo only ': 243,\n",
       " 'core': 244,\n",
       " 'played 2017': 245,\n",
       " '3 - 6': 246,\n",
       " 'rubbish': 247,\n",
       " 'horrible ': 248,\n",
       " 'garbage ': 249,\n",
       " 'smell : - - - - - - - : what : - - - - - - - ': 250,\n",
       " 'barely game ': 251,\n",
       " 'essen 2013': 252,\n",
       " 'min': 253,\n",
       " 'toy game ': 254,\n",
       " 'worst game i have ever played ': 255,\n",
       " 'random': 256,\n",
       " 'fan ': 257,\n",
       " 'video': 258,\n",
       " 'euro': 259,\n",
       " ' 2 players': 260,\n",
       " 'sold ': 261,\n",
       " 'gewonnen': 262,\n",
       " '1 - 4': 263,\n",
       " 'bleh': 264,\n",
       " 'childhood game ': 265,\n",
       " 'bad game ': 266,\n",
       " 'kickstarter exclusive content unethical : pushes buy game taking advantage fear miss it behaviour makes lose every interest games makes dislike them that rate explain reasons comments happens you rate games including one paste comment ': 267,\n",
       " 'bleh ': 268,\n",
       " 'essen 2012': 269,\n",
       " 'new': 270,\n",
       " 'yes': 271,\n",
       " 'comment updated ': 272,\n",
       " ' kps': 273,\n",
       " 'cup tea': 274,\n",
       " 'in : korea': 275,\n",
       " 'sold geekway 2018': 276,\n",
       " 'shrink': 277,\n",
       " '1 - 4 players': 278,\n",
       " 'gave away': 279,\n",
       " ' based one play ': 280,\n",
       " 'game collectible means gameplay fundamentally broken process figuring combinations better puzzle game sitting constructing team definition solitary play puzzle beyond business model collectible games deplorable form gambling targeted towards children adds benefit gameplay done specifically milk much money people possible ': 281,\n",
       " '2010': 282,\n",
       " 'traded ': 283,\n",
       " '2015': 284,\n",
       " 'fun party game': 285,\n",
       " '2016': 286,\n",
       " 'peg': 287,\n",
       " 'nice filler': 288,\n",
       " 'waste time ': 289,\n",
       " '2 - 10': 290,\n",
       " ' : thumbsdown : strategically shallow': 291,\n",
       " 'rating : 2 5 production value : 2 4 game collection 0 1': 292,\n",
       " '123': 293,\n",
       " 'good family game': 294,\n",
       " 'rated artwork game ! ': 295,\n",
       " 'thanks ': 296,\n",
       " 'inventory 2019 confirmed present': 297,\n",
       " 'lego': 298,\n",
       " 'much fun ': 299,\n",
       " 'choices game ': 300,\n",
       " 'boring ugly piece crap': 301,\n",
       " 'no no ': 302,\n",
       " 'great fun': 303,\n",
       " 'played version monopoly rating basic monopoly rate themed versions monopoly 4 accurately reflects desire play them ': 304,\n",
       " 'amazing game ': 305,\n",
       " 'rating based vague recollection ': 306,\n",
       " 'jugado': 307,\n",
       " 'essen 2015': 308,\n",
       " ' viter ': 309,\n",
       " 'great party game': 310,\n",
       " 'essen 2016': 311,\n",
       " 'good party game': 312,\n",
       " 'forgettable ': 313,\n",
       " 'home made': 314,\n",
       " 'sleeved wo not ': 315,\n",
       " 'excellent game ! ': 316,\n",
       " '2 - 8 players': 317,\n",
       " 'bought new ': 318,\n",
       " 'multiplayer solitaire': 319,\n",
       " 'much luck ': 320,\n",
       " 'worst game ever ! ': 321,\n",
       " 'abstract': 322,\n",
       " '3 4': 323,\n",
       " ' 2 ': 324,\n",
       " 'played game ': 325,\n",
       " 'players : best : ': 326,\n",
       " 'german edition': 327,\n",
       " 'played twice': 328,\n",
       " 'nope ': 329,\n",
       " 'reviewed mounted cloud': 330,\n",
       " 'm + a': 331,\n",
       " 'hate game': 332,\n",
       " 'expansions ': 333,\n",
       " 'long is ': 334,\n",
       " 'stan koniec sierpnia 2016 : stan koniec sierpnia 2017 : stan koniec sierpnia 2018 : ': 335,\n",
       " 'filler': 336,\n",
       " 'josh ': 337,\n",
       " ' edit - - the recent kickstarter defenders really soured games removed collection games opened tossed pile thrown trash refuse support giving game anyone else designed game without fix current loyal first time buyers sounds selfish take loyalty seriously desire play anything company again https : boardgamegeek com image 4594168 gradman20003 https : boardgamegeek com image 4594313 gradman20003 https : boardgamegeek com image 4594425 gradman20003': 338,\n",
       " 'ok ': 339,\n",
       " 'br4': 340,\n",
       " 'top shelf game ! ^ ^ ': 341,\n",
       " 'jansy': 342,\n",
       " '2017': 343,\n",
       " 'interesting': 344,\n",
       " 'party': 345,\n",
       " 'lame ': 346,\n",
       " 'classic ! ': 347,\n",
       " 'kid game ': 348,\n",
       " '2012': 349,\n",
       " 'probado': 350,\n",
       " 'trade': 351,\n",
       " 'nice': 352,\n",
       " 'verkocht': 353,\n",
       " 'base game medium level': 354,\n",
       " '2013': 355,\n",
       " 'base game': 356,\n",
       " 'overrated': 357,\n",
       " '2 - 4p': 358,\n",
       " 'boring game': 359,\n",
       " 'engelse regels originele opmaak': 360,\n",
       " 'gaming experience : mechanics : theme : artwork components : replayability : get table : - - - rounded total : - - - ': 361,\n",
       " 'hated': 362,\n",
       " 'best players': 363,\n",
       " 'opinion need make least one decision something called game activity fun right people game ': 364,\n",
       " 'fantastic game ! ': 365,\n",
       " 'unbelievably bad ': 366,\n",
       " 'fun little game ': 367,\n",
       " 'fun kids ': 368,\n",
       " 'love it ': 369,\n",
       " 'owned played': 370,\n",
       " 'selling': 371,\n",
       " 'played yet': 372,\n",
       " 'sell ': 373,\n",
       " 'masterpiece ': 374,\n",
       " ' b sold b ': 375,\n",
       " 'bought': 376,\n",
       " '2 - 5p': 377,\n",
       " 'fun : quality : - little influence - 3 ': 378,\n",
       " 'meh ! ': 379,\n",
       " 'storage ': 380,\n",
       " 'rated kids game': 381,\n",
       " '4 5': 382,\n",
       " 'perfect ': 383,\n",
       " 'game sport ': 384,\n",
       " 'see monopoly ': 385,\n",
       " 'bad game': 386,\n",
       " 'android version': 387,\n",
       " 'reviewed': 388,\n",
       " 'favorite': 389,\n",
       " 'simple fun': 390,\n",
       " 'rating previous june 2018 : ': 391,\n",
       " 'balance rating': 392,\n",
       " 'sleeved shelved kinda game': 393,\n",
       " ' nothing wrong game i am sure splendid affair however watching run reading reviews absolutely desire play ': 394,\n",
       " 'much luck': 395,\n",
       " 'diy': 396,\n",
       " ' 15': 397,\n",
       " 'children': 398,\n",
       " 'backed': 399,\n",
       " 'fun game': 400,\n",
       " 'mess ': 401,\n",
       " 'mindless game ': 402,\n",
       " ' inlineimg http : images boardgamegeek com images pic230833 jpg inlineimg ': 403,\n",
       " 'kinderspiele': 404,\n",
       " 'terrible game ': 405,\n",
       " 'soloable': 406,\n",
       " 'strategy': 407,\n",
       " 'really wish bgg would implement anti - shill measure alas us ': 408,\n",
       " 'played hope': 409,\n",
       " 'eur': 410,\n",
       " 'core sets': 411,\n",
       " 'boring ! ': 412,\n",
       " 'great fun ! ': 413,\n",
       " 'mecatol': 414,\n",
       " 'good kids': 415,\n",
       " 'piotru maciu ': 416,\n",
       " 'fun all ': 417,\n",
       " 'friend collection': 418,\n",
       " '2 4': 419,\n",
       " 'kickstarter backer': 420,\n",
       " 'unpunched': 421,\n",
       " 'localizaci n': 422,\n",
       " 'amazing game ! ': 423,\n",
       " 'hate': 424,\n",
       " 'tedious ': 425,\n",
       " 'favorite game': 426,\n",
       " 'painted': 427,\n",
       " 'much randomness ': 428,\n",
       " 'really game': 429,\n",
       " 'players ': 430,\n",
       " 'interesting ': 431,\n",
       " 'rating : 3 5 production value : 2 4 game collection 0 1': 432,\n",
       " 'guia': 433,\n",
       " 'hate it ': 434,\n",
       " 'perfect game ': 435,\n",
       " 'great ! ': 436,\n",
       " 'like game ': 437,\n",
       " 'texas': 438,\n",
       " 'one favorites': 439,\n",
       " ' geeksort - exclude': 440,\n",
       " 'game bad unfortunatly publisher customer service bad playing ystari pain pleasure think problems get game get complete etc play games anymore': 441,\n",
       " 'played game enjoy it ': 442,\n",
       " 'where game ': 443,\n",
       " 'need play more ': 444,\n",
       " 'complexity': 445,\n",
       " 'trash ': 446,\n",
       " 'nice game ': 447,\n",
       " 'pre - bgg ': 448,\n",
       " '2019 top 100 nominee': 449,\n",
       " 'amazing': 450,\n",
       " 'play ': 451,\n",
       " 'dull': 452,\n",
       " 'burned fire october 2017': 453,\n",
       " '3 - 5 players': 454,\n",
       " '2p : solo : ': 455,\n",
       " 'living room': 456,\n",
       " 'luques': 457,\n",
       " '2 - 6p': 458,\n",
       " 'complexity : ': 459,\n",
       " 'much fun ! ': 460,\n",
       " 'never': 461,\n",
       " 'game group': 462,\n",
       " 'like game all ': 463,\n",
       " 'heike': 464,\n",
       " 'bga': 465,\n",
       " 'dublin': 466,\n",
       " '2 - 7 players': 467,\n",
       " ' ! ! ': 468,\n",
       " 'conventions': 469,\n",
       " 'favourite game': 470,\n",
       " 'one worst games ever played ': 471,\n",
       " 'avalon hill': 472,\n",
       " 'puzzle game ': 473,\n",
       " 'backed kickstarter ': 474,\n",
       " 'classic game ': 475,\n",
       " ' 4 ': 476,\n",
       " 'keep 2018 ': 477,\n",
       " 'dice': 478,\n",
       " 'hobby': 479,\n",
       " 'eng niezale na j zykowo ': 480,\n",
       " 'i would rather play url = https : boardgamegeek com boardgame 206718 ethnos forums 66 ethnos url ': 481,\n",
       " 'best : ': 482,\n",
       " 'markiert': 483,\n",
       " 'super ! ': 484,\n",
       " 'decent filler ': 485,\n",
       " '2018 : ': 486,\n",
       " ' : thumbsdown : prolonged playtime : snore : ': 487,\n",
       " 'thrift store find': 488,\n",
       " 'family owned': 489,\n",
       " 'good condition ': 490,\n",
       " 'one play great condition ': 491,\n",
       " 'favorite game ': 492,\n",
       " 'word': 493,\n",
       " 'choices ': 494,\n",
       " 'stored kids stuff': 495,\n",
       " 'two thumbs up ': 496,\n",
       " 'light fun ': 497,\n",
       " 'sold ! ': 498,\n",
       " '8th light jason maxwell nope ': 499,\n",
       " 'much game ': 500,\n",
       " 'masterpiece': 501,\n",
       " 'origins 2018': 502,\n",
       " 'wouldn t turn offer play game niche receive 10 neat awesome unique play time where excellent game frequently sees play okay rating games played liked don t need play frequently rarely played sit shelf long time nearly unplayable number reasons ': 503,\n",
       " 'in : poland': 504,\n",
       " 'unplayable': 505,\n",
       " 'dan balance overhype game ': 506,\n",
       " ' 3 ': 507,\n",
       " '2 - player': 508,\n",
       " 'amazing ': 509,\n",
       " 'strategy tactics': 510,\n",
       " 'oop': 511,\n",
       " 'marc': 512,\n",
       " 'hum ': 513,\n",
       " 'burn em': 514,\n",
       " ' - - ': 515,\n",
       " 'kid': 516,\n",
       " 'cool ': 517,\n",
       " 'boring game ': 518,\n",
       " 'game here ': 519,\n",
       " 'played pre - bgg ': 520,\n",
       " 'expansions : ': 521,\n",
       " 'depth - components - art - theme - replayability - ': 522,\n",
       " 'rating based one play ': 523,\n",
       " 'rating': 524,\n",
       " 'fun kids': 525,\n",
       " 'play kids ': 526,\n",
       " 'balance': 527,\n",
       " 'awful game ': 528,\n",
       " 'wargame': 529,\n",
       " 'filler ': 530,\n",
       " 'snore ': 531,\n",
       " 'brett': 532,\n",
       " '3 - 5': 533,\n",
       " 'nothing special ': 534,\n",
       " 'dexterity game': 535,\n",
       " 'silly fun ': 536,\n",
       " '15 ': 537,\n",
       " 'played 2018': 538,\n",
       " 'fun family game ! ': 539,\n",
       " 'extra room': 540,\n",
       " 'love it sell even unplayed ': 541,\n",
       " '2 - 4 spieler': 542,\n",
       " 'came here people rating mature themed games like kd : m hate mature them games theme boring ! ': 543,\n",
       " '1 - 6 players': 544,\n",
       " 'solo playable': 545,\n",
       " 'pointless': 546,\n",
       " 'android': 547,\n",
       " 'players : ': 548,\n",
       " 'do not ': 549,\n",
       " 'like abstracts ': 550,\n",
       " 'one favorite games time ': 551,\n",
       " 'okay ': 552,\n",
       " 'awful awful ': 553,\n",
       " 'ndne': 554,\n",
       " 'fantastic game ': 555,\n",
       " 'sold it ': 556,\n",
       " 'wife rating : ': 557,\n",
       " 'dumb ': 558,\n",
       " 'anything serial killing gets low marks possible ': 559,\n",
       " 'gus': 560,\n",
       " '2 - 3': 561,\n",
       " 'k k': 562,\n",
       " 'thrifted': 563,\n",
       " 'see gameid = 122522 ': 564,\n",
       " 'initial impression limited plays': 565,\n",
       " 'math trade': 566,\n",
       " '1 - 2': 567,\n",
       " 'fast fun ': 568,\n",
       " 'favorite game ! ': 569,\n",
       " 'fun : quality : - limited influence - 1 ': 570,\n",
       " 'classic reason ': 571,\n",
       " 'fun game ! ': 572,\n",
       " 'megan veto': 573,\n",
       " 'mia': 574,\n",
       " 'trivia': 575,\n",
       " 'disappointing ': 576,\n",
       " 'simple ': 577,\n",
       " 'kickstarter version': 578,\n",
       " 'kickstarter ': 579,\n",
       " '2 - 6 30m': 580,\n",
       " 'bremen': 581,\n",
       " 'arbitrary ': 582,\n",
       " 'type game': 583,\n",
       " '20 ': 584,\n",
       " 'erast : ewejka : ': 585,\n",
       " 'superb': 586,\n",
       " 'players : 2 - 4': 587,\n",
       " 'yuck ! ': 588,\n",
       " 'would rather play phone ': 589,\n",
       " '1 - 5': 590,\n",
       " ' home': 591,\n",
       " 'nope': 592,\n",
       " 'waste time': 593,\n",
       " 'german': 594,\n",
       " 'use': 595,\n",
       " 'trick - taking': 596,\n",
       " 'ghc': 597,\n",
       " 'correcting rating user malain put random bunch games reason really damaging ranking unknown games ratings ': 598,\n",
       " 'essayer ': 599,\n",
       " 'print play version': 600,\n",
       " 'bnis': 601,\n",
       " 'picassojac : ': 602,\n",
       " 'counting plays': 603,\n",
       " ' : ': 604,\n",
       " '2014': 605,\n",
       " 'like game': 606,\n",
       " 'i m kickstarter backer game refund information all ': 607,\n",
       " 'tedious': 608,\n",
       " 'no ! ': 609,\n",
       " 'game me ': 610,\n",
       " 'amazing ! ': 611,\n",
       " 'solitaire': 612,\n",
       " 'funny ': 613,\n",
       " 'heavy': 614,\n",
       " 'fatte alcune partite non registrate': 615,\n",
       " 'good ! ': 616,\n",
       " 'done': 617,\n",
       " 'joueurs': 618,\n",
       " 'yawn ! ': 619,\n",
       " 'played ': 620,\n",
       " 'plays recorded': 621,\n",
       " 'played years ': 622,\n",
       " 'german version': 623,\n",
       " 'medium': 624,\n",
       " 'sale box': 625,\n",
       " 'ursus': 626,\n",
       " 'slow': 627,\n",
       " 'me dubai': 628,\n",
       " 'steam': 629,\n",
       " 'great family game ': 630,\n",
       " '30 ': 631,\n",
       " ' pending ': 632,\n",
       " 'rated children game ': 633,\n",
       " 'solid game ': 634,\n",
       " 'initial rating': 635,\n",
       " 'initial impression; limited plays ': 636,\n",
       " 'played while particularly fond memories ': 637,\n",
       " 'war': 638,\n",
       " 'learning : teaching : comment : ': 639,\n",
       " '2 - 8p': 640,\n",
       " 'memory game': 641,\n",
       " 'archived': 642,\n",
       " 'cooperative game': 643,\n",
       " 'theme rip': 644,\n",
       " 'filou': 645,\n",
       " 'englisch': 646,\n",
       " 'much game here ': 647,\n",
       " 'fantastic ': 648,\n",
       " 'paul': 649,\n",
       " 'sum fun': 650,\n",
       " 'italy': 651,\n",
       " 'another soulless euro ': 652,\n",
       " 'poor': 653,\n",
       " 'gespielt': 654,\n",
       " 'terrible game': 655,\n",
       " 'interesting game ': 656,\n",
       " 'wow ! ': 657,\n",
       " 'punched played': 658,\n",
       " 'pure garbage ': 659,\n",
       " 'belongs children': 660,\n",
       " 'really like game ': 661,\n",
       " 'played lot kid growing up enjoyed game kid playing adult unless spend time niece nephew etc possibly non - gamers so copy game question copy since switch american board games euro board games many better games playing game regular basis waste time ': 662,\n",
       " 'see munchkin': 663,\n",
       " 'funny': 664,\n",
       " 'one favorites ! ': 665,\n",
       " 'good filler game ': 666,\n",
       " 'worker placement': 667,\n",
       " 'bored': 668,\n",
       " 'broken game ': 669,\n",
       " 'played online': 670,\n",
       " 'great party game ': 671,\n",
       " 'played yucata': 672,\n",
       " 'sam ': 673,\n",
       " 'rating reflects fact would never want play buy game based bad business practices publisher encourage consumers care things play buy game ': 674,\n",
       " 'complicated': 675,\n",
       " '2 - 8': 676,\n",
       " 'unplayable another language': 677,\n",
       " 'junk ': 678,\n",
       " 'see review': 679,\n",
       " 'yuck': 680,\n",
       " 'sammlung': 681,\n",
       " 'good family game ': 682,\n",
       " ' inlineimg http : images boardgamegeek com images pic230790 jpg inlineimg ': 683,\n",
       " '2009': 684,\n",
       " 'complet': 685,\n",
       " 'matame cami n ': 686,\n",
       " 'donated ': 687,\n",
       " 'laurence': 688,\n",
       " 'unplayable ': 689,\n",
       " 'nis also sale ': 690,\n",
       " 'non - hobby': 691,\n",
       " 'meaningful decisions ': 692,\n",
       " 'boardgame ': 693,\n",
       " 'heavy ': 694,\n",
       " 'absolutely love game ': 695,\n",
       " 'smell : - - - - : - - - - - - - - - - ': 696,\n",
       " 'good party game ': 697,\n",
       " 'great kids game': 698,\n",
       " 'best ': 699,\n",
       " 'meeple realty insert': 700,\n",
       " 'light ': 701,\n",
       " 'poor ': 702,\n",
       " 'classic word game ': 703,\n",
       " 'one play': 704,\n",
       " 'like : dislike : ': 705,\n",
       " 'patryk': 706,\n",
       " 'alan': 707,\n",
       " ' 20': 708,\n",
       " 'amazing game': 709,\n",
       " 'clst': 710,\n",
       " 'best game': 711,\n",
       " 'give away': 712,\n",
       " 'campaign story': 713,\n",
       " 'excellent condition pieces included intact ': 714,\n",
       " 'gioco italiano': 715,\n",
       " 'simple fun ': 716,\n",
       " 'perfection ': 717,\n",
       " 'get it ': 718,\n",
       " 'like lego games really targeted children great thing games changed whatever want lego all played once purchased parts lego collection ': 719,\n",
       " 'broken token insert': 720,\n",
       " 'way long': 721,\n",
       " 'great ': 722,\n",
       " 'competitive card game filler': 723,\n",
       " 'gossip witchhunts shitty way spend evening ': 724,\n",
       " 'creator game keeps pestering change rating have changing 1 intense annoyance bothered time creator small - time virtually unheard of game real bearing world board games get it nobody cares ! ': 725,\n",
       " 'tier': 726,\n",
       " 'random fun ': 727,\n",
       " 'br2': 728,\n",
       " 'first play rating : 5 0': 729,\n",
       " 'buy this ': 730,\n",
       " 'this ': 731,\n",
       " ' b ameritrash b ': 732,\n",
       " 'max best players': 733,\n",
       " 'rated children game': 734,\n",
       " ' : thumbsdown : dramatic dice : yuk : outset variable input variable output variable : cry : : gulp : asymmetry direct conflict welcome addition deck pool building genre adding randomness top randomness major turnoff me i would rather play url = https : www boardgamegeek com boardgame 123607 puzzle - strike - third - edition puzzle strike url ': 735,\n",
       " 'volledig': 736,\n",
       " 'solid game': 737,\n",
       " 'tba': 738,\n",
       " 'outstanding ! ': 739,\n",
       " ' game ': 740,\n",
       " ' sara': 741,\n",
       " 'excellent condition ': 742,\n",
       " 'work': 743,\n",
       " 'enfants': 744,\n",
       " 'trashed': 745,\n",
       " 'loan': 746,\n",
       " 'provisional rating one play ': 747,\n",
       " 'con traduccion': 748,\n",
       " 'much ': 749,\n",
       " ' : shake : ': 750,\n",
       " 'beautiful game': 751,\n",
       " 'munchkin': 752,\n",
       " 'rated game': 753,\n",
       " 'sleeve': 754,\n",
       " '2011': 755,\n",
       " 'aucun sleeve': 756,\n",
       " 'unremarkable ': 757,\n",
       " 'polish edition': 758,\n",
       " 'solo variant': 759,\n",
       " 'horrible horrible game ': 760,\n",
       " 'dry ': 761,\n",
       " 'see': 762,\n",
       " ' o : robert ': 763,\n",
       " 'jan': 764,\n",
       " 'criterion rating games http : boardgamegeek com geeklist 147053 item 2300390 item2300390': 765,\n",
       " 'vendido': 766,\n",
       " 'bsw': 767,\n",
       " 'never want see game again ': 768,\n",
       " ' game choice make gameplay color shape picture pawn want use start game rest game 100 random game opinion no choice cheat end tedium valid in - game choice and no games like spinners dexterity games try cheat attempting manipulate outcome spin redeeming quality activies educational value young children i e teaching rudimentary skills pattern shape color recognition counting also used teach basic principles gaming like taking turns following rules rolling dice carefully draw card do says discard gracious winning losing games take long time finish opposite effect teaching children games fun ': 769,\n",
       " '3 - 8 players': 770,\n",
       " 'painful ': 771,\n",
       " ' : star : : star : : nostar : : nostar : : nostar : ': 772,\n",
       " 'game sucks ': 773,\n",
       " 'essen 2008': 774,\n",
       " 'much fun': 775,\n",
       " 'family collection': 776,\n",
       " ' 2 min ': 777,\n",
       " 'played prior bgg': 778,\n",
       " 'expansion ': 779,\n",
       " 'received trade': 780,\n",
       " 'mini box': 781,\n",
       " 'mag collectie verlaten': 782,\n",
       " 'tabletop': 783,\n",
       " 'rental : 10': 784,\n",
       " 'played meet - up event ': 785,\n",
       " 'game best players': 786,\n",
       " '20m': 787,\n",
       " '50 + plays': 788,\n",
       " 'complete utter fiddly mess ! ': 789,\n",
       " 'never liked game ': 790,\n",
       " 'folijki': 791,\n",
       " 'plays ': 792,\n",
       " 'brilliant ': 793,\n",
       " 'game plays itself ': 794,\n",
       " 'incomplete': 795,\n",
       " 'rental : 50': 796,\n",
       " 'keep top': 797,\n",
       " '2 - 10 players': 798,\n",
       " 'regel': 799,\n",
       " 'legacy': 800,\n",
       " 'mint still shrink wrap ': 801,\n",
       " 'same ': 802,\n",
       " 'almost pure luck strategy ': 803,\n",
       " 'verkauft': 804,\n",
       " 'good filler': 805,\n",
       " 'part second pack - o - games kickstarter': 806,\n",
       " 'base game player approved year last played : 2019': 807,\n",
       " 'vasel': 808,\n",
       " 'random action required player ': 809,\n",
       " 'plays pre 2017': 810,\n",
       " 'worst game ever': 811,\n",
       " 'labyrinth': 812,\n",
       " '2 - 2': 813,\n",
       " 'need plays ': 814,\n",
       " 'great kids ': 815,\n",
       " 'plays : best for : non - gamer gamer hangouts': 816,\n",
       " 'best game ever played ': 817,\n",
       " 'luck': 818,\n",
       " 'nah ': 819,\n",
       " 'weg': 820,\n",
       " 'hidden roles': 821,\n",
       " 'android app actual game still love game though want buy actual game one day ': 822,\n",
       " 'thrift store find ': 823,\n",
       " 'sleeves rules summary': 824,\n",
       " ' color = 00cc99 co color ': 825,\n",
       " 'need play': 826,\n",
       " 'purchased': 827,\n",
       " 'wow': 828,\n",
       " 'list': 829,\n",
       " 'boooring ': 830,\n",
       " 'travel edition': 831,\n",
       " 'small': 832,\n",
       " 'much game': 833,\n",
       " 'annoying ': 834,\n",
       " 'horrid ': 835,\n",
       " 'rerated': 836,\n",
       " 'dated ': 837,\n",
       " 'tan ': 838,\n",
       " 'gave away ': 839,\n",
       " 'chopping block': 840,\n",
       " 'try': 841,\n",
       " 'due games workshop recent decision force bgg remove files supporting games removed 10 ranking game greatly enjoy playing game longer wish contribute game high ranking bgg reverses stand restore ranking ': 842,\n",
       " 'must': 843,\n",
       " 'this is not game ': 844,\n",
       " 'used': 845,\n",
       " 'blech ': 846,\n",
       " 'jamie owns': 847,\n",
       " 'plays : 2 - 4 best for : non - gamer gamer hangouts': 848,\n",
       " 'vee ': 849,\n",
       " 'played twice ': 850,\n",
       " 'correcting rating user malain put random bunch games reason some hints racism though really damaging ranking unknown games ratings ': 851,\n",
       " 'really ': 852,\n",
       " 'ratings': 853,\n",
       " 'rating purely based solo experience ': 854,\n",
       " 'yucata': 855,\n",
       " 'grupo': 856,\n",
       " 'argh ! ': 857,\n",
       " '1 - 5 players': 858,\n",
       " 'one best games ever played': 859,\n",
       " 'game awful ': 860,\n",
       " 'dreadful ': 861,\n",
       " 'storage box': 862,\n",
       " 'christmas 2018': 863,\n",
       " 'casual': 864,\n",
       " 'kids love it ': 865,\n",
       " ' : thumbsup : intrinsic interaction : thumbsdown : prolonged playtime : snore : : thumbsdown : dice drama : yuk : ': 866,\n",
       " 'one favorites ': 867,\n",
       " 'solved': 868,\n",
       " 'brilliant ! ': 869,\n",
       " 'kickstarter edition ': 870,\n",
       " 'gameplay replay ability length components fun factor': 871,\n",
       " 'yosef': 872,\n",
       " 'impressed ': 873,\n",
       " 'kleine fische': 874,\n",
       " 'same means good dice bad game': 875,\n",
       " 'shit ': 876,\n",
       " 'greenfield games auction': 877,\n",
       " 'fun filler game ': 878,\n",
       " 'cdg': 879,\n",
       " 'luckfest ': 880,\n",
       " 'game activity ': 881,\n",
       " 'decision making ': 882,\n",
       " 'balancing fake ratings': 883,\n",
       " 'played kid': 884,\n",
       " 'players : 2 - 5': 885,\n",
       " 'munchkin ': 886,\n",
       " 'one 10s': 887,\n",
       " 'disturbing ': 888,\n",
       " 'csi': 889,\n",
       " 'love game ! ! ! ': 890,\n",
       " 'initial impression ': 891,\n",
       " 'silly ': 892,\n",
       " 'painted ': 893,\n",
       " 'sold fantasy books games fairview heights bazaar 2018 ! ': 894,\n",
       " 'favorite filler ': 895,\n",
       " 'played once excellent condition': 896,\n",
       " 'game worst ': 897,\n",
       " 'nice game ! ': 898,\n",
       " ' : thumbsdown : dramatic dice : yuk : ': 899,\n",
       " 'ashley played': 900,\n",
       " 'played game love it ': 901,\n",
       " 'nonsense ': 902,\n",
       " '2 - 5 players best': 903,\n",
       " 'played dislike ': 904,\n",
       " '1 - 2 players': 905,\n",
       " 'broken boring ': 906,\n",
       " 'okay': 907,\n",
       " 'picassojac : 6 75': 908,\n",
       " 'work 2p ': 909,\n",
       " 'sleeves needed': 910,\n",
       " 'zzzzzz': 911,\n",
       " 'see black stories ': 912,\n",
       " 'fun quick filler ': 913,\n",
       " 'booooring ! ': 914,\n",
       " 'supposed fun ': 915,\n",
       " 'latcg standard perfect fit': 916,\n",
       " 'always fun ': 917,\n",
       " 'wersja': 918,\n",
       " 'pnp ': 919,\n",
       " 'fun kids game': 920,\n",
       " 'insert': 921,\n",
       " 'liz owns': 922,\n",
       " 'terrible ! ': 923,\n",
       " 'christmas 2016': 924,\n",
       " 'donated flgs ': 925,\n",
       " 'favorite ': 926,\n",
       " '2017 decembre': 927,\n",
       " 'kickstarted ! ': 928,\n",
       " 'sjg': 929,\n",
       " 'auctioned': 930,\n",
       " 'weight plays best 2 - 4 players': 931,\n",
       " 'nathan ': 932,\n",
       " 'mont ': 933,\n",
       " 'sell trade': 934,\n",
       " '10 00': 935,\n",
       " 'interesting hard decisions ': 936,\n",
       " 'great wwii grand strategic games there also risk neither ': 937,\n",
       " 'monopoly': 938,\n",
       " 'here let design sirlin game together : take existing game already quite successful add heavy dose randomness add gratuitous special powers write designer diary game fixes existing game serve hot bottom line one skip it ': 939,\n",
       " 'great family game ! ': 940,\n",
       " '1 - 1': 941,\n",
       " 'fun : quality : - much influence + 1 - few options - 1 ': 942,\n",
       " 'family favorite ': 943,\n",
       " 'spieler': 944,\n",
       " 'gave pub': 945,\n",
       " '30m': 946,\n",
       " 'b st spelare': 947,\n",
       " 'kdj 2017 yeah right pick tic - tac - toe next time low est quality components poor rulebook fun all ! play any real escape game way better commercial rip - off speaking rip - offs : also strongly detest concept ripping game apart playing makes high replayability ': 948,\n",
       " 'simply awful ': 949,\n",
       " 'silly fun': 950,\n",
       " 'really love game ': 951,\n",
       " 'comment': 952,\n",
       " 'gift ': 953,\n",
       " 'cool game': 954,\n",
       " 'gave nephew ': 955,\n",
       " 'thrifty santa 2018': 956,\n",
       " 'recibido por por gdm': 957,\n",
       " 'unauthorized copy steals royalty checks game designer ': 958,\n",
       " 'part shared collection': 959,\n",
       " 'really bad ': 960,\n",
       " 'okay filler game strategy involved ': 961,\n",
       " 'proof new': 962,\n",
       " '2017 novembre': 963,\n",
       " 'venda': 964,\n",
       " 'long random ': 965,\n",
       " 'far long far random ': 966,\n",
       " 'best party game ever ': 967,\n",
       " 'group game': 968,\n",
       " 'received gift': 969,\n",
       " 'kid game': 970,\n",
       " ' 10 ': 971,\n",
       " 'complete good condition ': 972,\n",
       " '005': 973,\n",
       " 'children game ages': 974,\n",
       " 'kids like it ': 975,\n",
       " ' + + + ': 976,\n",
       " 'classic fun ': 977,\n",
       " 'tactical battle': 978,\n",
       " ' size = 12 color = 009900 b mike b color size ': 979,\n",
       " 'waste time money ': 980,\n",
       " 'achat neuf': 981,\n",
       " 'nice new factions': 982,\n",
       " 'rated': 983,\n",
       " 'originality 0 0 1 0 theme 0 0 0 5 pure fun 0 0 1 0 replayability 0 0 1 0 strategy luck ratio 0 0 0 5 scalability 0 5 0 5 parity 0 0 0 5 overall 0 5 5 0': 984,\n",
       " 'app only ': 985,\n",
       " 'really really thing ': 986,\n",
       " 'weak ': 987,\n",
       " 'used good condition': 988,\n",
       " 'great two players ': 989,\n",
       " 'complete ': 990,\n",
       " 'quick fun ': 991,\n",
       " 'abstract me ': 992,\n",
       " 'ccgs poison ': 993,\n",
       " 'rental : 35': 994,\n",
       " 'good usually willing play ': 995,\n",
       " 'like dexterity games with exceptions ': 996,\n",
       " 'good original ': 997,\n",
       " 'fun replay component theme': 998,\n",
       " 'donald owns': 999,\n",
       " 'tentative rating': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YPt3VfZwCcqG",
    "outputId": "536db1ae-1998-4fb6-80f3-72905dadc89e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our vocaulary is  187628\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"The size of our vocaulary is \",vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlDP4kRQ78tU"
   },
   "source": [
    "### Preparing classification labels\n",
    "\n",
    "Since our classifiction is a multi class classification we need to find the unqiue labels and convert them to categorical tensor so that our NN model can understand it. I am using skleans label encoder to conver the data into categorical tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LNYYfC9KCcqJ",
    "outputId": "80dc56cb-44e0-4587-ae6e-6a447cd78405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "num_classes = len(counts)\n",
    "print(unique)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTpeX3xT78tX"
   },
   "source": [
    "I have 10 classes. Now i need to convert this numerical data into categorical tensors. A categorical tensors are binary tensor with columns equal to num of classes. \n",
    "\n",
    "For our case we have 10 classes so for a label with value 8 will be equal to:\n",
    "\n",
    "[0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "B0O0Q_ZWCcqP",
    "outputId": "da6a211e-a5e8-431a-dcb6-e344dc06f321"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(140000, 10)\n"
     ]
    }
   ],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "y_test = Encoder.fit_transform(y_test)\n",
    "print(y_train.shape)\n",
    "print(to_categorical(y_train)[1])\n",
    "print(to_categorical(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNVY5zbsCcqT"
   },
   "outputs": [],
   "source": [
    "I have used encoder to convert my train data into categorical tensor. As we can see before the data was of 1 dim now it is 2 dim . The 10 colums signify which class the data belong to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DyRmZuNN78tm"
   },
   "source": [
    "## Neural Network Model\n",
    "\n",
    "Now comes the brain our of classifier , the neural network model. There are many neural network architectures but for this project I am going to use a shallow NN , a Deep NN , a CNN and a CNN with regularization. \n",
    "\n",
    "For all my models i am going to use 'softmax' activation function for output layer . Why softmax you ask , because we are doing multi class classification . Softmax function gives probabilites for all the classes and the one with the maximum probabilty is our preditiction . \n",
    "\n",
    "For loss we are going to use 'keras.loss.categorical_crossentropy' since it is a softmax loss function which is used for multi class prediction.\n",
    "\n",
    "For optimizer I am going to use 'keras.optimizer.adam'. Adam is one of the fastest and accurate optimizer for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9112L78J78tr"
   },
   "source": [
    "## Shallow NN \n",
    "\n",
    "Here I have 2 dense keras.layers in a functional model.The first layer will be  input layer to get the input and pass it to the other layers. For text classification we need to have an embedding layer . An embedding layer initializes random weights for all the words and will learn embedding for all the words. we need to set the size the of embedding matrix , here i will be using 50. This size is used represent the embedding of the words. The total trainable paramaters are 50 * max_features. Then I add a flatten layer to convert the 2 dim ouput of embedding layer to 1 dim . Finally I use 2 dense layers or fully connected layers to train and get my prediction. \n",
    "\n",
    "number of nodes for dense layer1 = 512\n",
    "number of nodes for dense layer2 or prediction = Num of classes\n",
    "\n",
    "The activation function that I am using for input layer is Relu . Relu is Rectified Linear Unit.The function returns 0 if it receives any negative input, but for any positive value  x it returns that value back. So it can be written as  f(x)=max(0,x).\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "z0_biTYF78t4",
    "outputId": "df7b6b40-179c-4189-919f-929820a4160f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 50)           500000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2560512   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 3,065,642\n",
      "Trainable params: 3,065,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inputs = Input(shape=(max_len, ))\n",
    "embedding_layer = Embedding(max_features,50, input_length=max_len)(Inputs)\n",
    "x = Flatten()(embedding_layer)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model1 = Model(inputs=[Inputs], outputs=predictions)\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ofmc_SQg78t7"
   },
   "source": [
    "## Deep NN \n",
    "\n",
    "Here I have 4 dense keras.layers in a functional model. The model is similar to the above model but the number of dense layers I used increased . This makes the networks a deep NN as the number of hidden layers are more. The nodes in each layer are  128,100, 32 and num_classes.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "c1nOV29v78t8",
    "outputId": "004e8158-a45a-44cb-cad1-ff48edf74d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 50)           500000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               640128    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,156,590\n",
      "Trainable params: 1,156,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inputs = Input(shape=(max_len, ))\n",
    "embedding_layer = Embedding(max_features,50, input_length=max_len)(Inputs)\n",
    "x = Flatten()(embedding_layer)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model2 = Model(inputs=[Inputs], outputs=predictions)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NtPXA2578uJ"
   },
   "source": [
    "## Deep CNN without regularization\n",
    "\n",
    "I am using a functional model to create a network with 1 embedding layer, 2 conv2D layers and 1 dense layer. The filters I used for convolutional layers are 2 and 3 and num of filters i used is 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyy1G8bv78uK"
   },
   "outputs": [],
   "source": [
    "embedding_d = 50 \n",
    "filter_sizes = [2,3]\n",
    "Num_f = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "fnv-YMMl3GEx",
    "outputId": "f860fb4b-a02c-470d-bd3f-f1396595f43b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 100, 50)      500000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 100, 50, 1)   0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 99, 1, 16)    1616        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 98, 1, 16)    2416        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 16)     0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 16)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 1, 16)     0           max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 32)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           330         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 504,362\n",
      "Trainable params: 504,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inputs = Input(shape=(max_len,))\n",
    "x = Embedding(max_features, embedding_d)(Inputs)\n",
    "x = Reshape((max_len, embedding_d, 1))(x)\n",
    "maxpool_pool = []\n",
    "for i in range(len(filter_sizes)):\n",
    "    conv = Conv2D(Num_f, kernel_size=(filter_sizes[i], embedding_d),\n",
    "                                     kernel_initializer='he_normal', activation='relu')(x)\n",
    "    maxpool_pool.append(MaxPool2D(pool_size=(max_len - filter_sizes[i] + 1, 1))(conv))\n",
    "x = Concatenate(axis=1)(maxpool_pool)   \n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model3 = Model(inputs=[Inputs], outputs=predictions)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aFbU774L78uQ"
   },
   "source": [
    "## Deep CNN with regularization\n",
    "\n",
    "I am using a functional model to create a network with 1 embedding layer, 2 conv2D layers and 1 dense layer. The filters I used for convolutional layers are 2 and 3 and num of filters i used is 50. Here i am using l1 regularization to improve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "Cjt6QkcV78uS",
    "outputId": "8aa32d9f-0ee7-4701-f683-7bcfe931f1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 100, 100)     1000000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 100, 100, 1)  0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 99, 1, 64)    12864       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 98, 1, 64)    19264       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 64)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2, 1, 64)     0           max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 128)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           1290        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,033,418\n",
      "Trainable params: 1,033,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_d = 100 \n",
    "filter_sizes = [2,3]\n",
    "Num_f = 64\n",
    "\n",
    "Inputs = Input(shape=(max_len,))\n",
    "x = Embedding(max_features, embedding_d)(Inputs)\n",
    "x = Reshape((max_len, embedding_d, 1))(x)\n",
    "maxpool_pool = []\n",
    "for i in range(len(filter_sizes)):\n",
    "    conv = Conv2D(Num_f, kernel_size=(filter_sizes[i], embedding_d), activation='relu',kernel_regularizer = l1(0.0001))(x)\n",
    "    maxpool_pool.append(MaxPool2D(pool_size=(max_len - filter_sizes[i] + 1, 1))(conv))\n",
    "x = Concatenate(axis=1)(maxpool_pool)   \n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "model4 = Model(inputs=[Inputs], outputs=predictions)\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training all the models\n",
    "\n",
    "Here I am training all my models using the training data. I am using callback to make sure that the best accurcay is recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "CsZc65Ns6ocq",
    "outputId": "d6344540-dd39-4015-f03f-adec8fd202aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126000 samples, validate on 14000 samples\n",
      "Epoch 1/4\n",
      "126000/126000 [==============================] - 81s 641us/step - loss: 2.0908 - accuracy: 0.1995 - val_loss: 2.0661 - val_accuracy: 0.2076\n",
      "Epoch 2/4\n",
      "   304/126000 [..............................] - ETA: 1:19 - loss: 1.9921 - accuracy: 0.2368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126000/126000 [==============================] - 78s 623us/step - loss: 2.0281 - accuracy: 0.2267 - val_loss: 2.0598 - val_accuracy: 0.2116\n",
      "Epoch 3/4\n",
      "126000/126000 [==============================] - 78s 620us/step - loss: 1.9310 - accuracy: 0.2690 - val_loss: 2.1113 - val_accuracy: 0.2080\n",
      "Epoch 4/4\n",
      "126000/126000 [==============================] - 77s 609us/step - loss: 1.7550 - accuracy: 0.3469 - val_loss: 2.2744 - val_accuracy: 0.1991\n"
     ]
    }
   ],
   "source": [
    "filepath=\"model1.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history1 = model1.fit(x_train_1, to_categorical(y_train), batch_size = 16, epochs = 4, validation_split = .1,callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "cDFVYPL_XqQl",
    "outputId": "10f7db45-ecd6-44b6-bf06-b10232b5524e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126000 samples, validate on 14000 samples\n",
      "Epoch 1/4\n",
      "126000/126000 [==============================] - 50s 394us/step - loss: 2.0976 - accuracy: 0.1946 - val_loss: 2.0711 - val_accuracy: 0.2134\n",
      "Epoch 2/4\n",
      "   448/126000 [..............................] - ETA: 48s - loss: 1.9714 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126000/126000 [==============================] - 48s 379us/step - loss: 2.0377 - accuracy: 0.2191 - val_loss: 2.0573 - val_accuracy: 0.2086\n",
      "Epoch 3/4\n",
      "126000/126000 [==============================] - 48s 380us/step - loss: 2.0013 - accuracy: 0.2309 - val_loss: 2.0686 - val_accuracy: 0.2106\n",
      "Epoch 4/4\n",
      "126000/126000 [==============================] - 49s 387us/step - loss: 1.9466 - accuracy: 0.2505 - val_loss: 2.0999 - val_accuracy: 0.2067\n"
     ]
    }
   ],
   "source": [
    "filepath=\"model2.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history2 = model2.fit(x_train_1, to_categorical(y_train), batch_size = 16, epochs = 4, validation_split = .1,callbacks=[checkpointer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "fALdbTsM78us",
    "outputId": "2202c018-bca0-4a12-eefc-9e3a904fbc93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126000 samples, validate on 14000 samples\n",
      "Epoch 1/4\n",
      "126000/126000 [==============================] - 51s 406us/step - loss: 2.0974 - accuracy: 0.2026 - val_loss: 2.0600 - val_accuracy: 0.2140\n",
      "Epoch 2/4\n",
      "   400/126000 [..............................] - ETA: 52s - loss: 2.0776 - accuracy: 0.1900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126000/126000 [==============================] - 51s 405us/step - loss: 2.0540 - accuracy: 0.2173 - val_loss: 2.0469 - val_accuracy: 0.2186\n",
      "Epoch 3/4\n",
      "126000/126000 [==============================] - 53s 417us/step - loss: 2.0433 - accuracy: 0.2205 - val_loss: 2.0448 - val_accuracy: 0.2205\n",
      "Epoch 4/4\n",
      "126000/126000 [==============================] - 51s 403us/step - loss: 2.0369 - accuracy: 0.2226 - val_loss: 2.0462 - val_accuracy: 0.2187\n"
     ]
    }
   ],
   "source": [
    "filepath=\"model3.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history3 = model3.fit(x_train_1, to_categorical(y_train), batch_size = 16, epochs = 4, validation_split = .1,callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "Vqxqppel78uu",
    "outputId": "2fb2023e-f718-4fa9-d28d-082e90cc2a45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8999 samples, validate on 1000 samples\n",
      "Epoch 1/4\n",
      "8999/8999 [==============================] - 6s 688us/step - loss: 2.0670 - accuracy: 0.2211 - val_loss: 2.0824 - val_accuracy: 0.2140\n",
      "Epoch 2/4\n",
      " 256/8999 [..............................] - ETA: 6s - loss: 2.0530 - accuracy: 0.2422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 7s 726us/step - loss: 2.0502 - accuracy: 0.2282 - val_loss: 2.0947 - val_accuracy: 0.2310\n",
      "Epoch 3/4\n",
      "8999/8999 [==============================] - 6s 622us/step - loss: 2.0366 - accuracy: 0.2336 - val_loss: 2.1071 - val_accuracy: 0.2230\n",
      "Epoch 4/4\n",
      "8999/8999 [==============================] - 5s 601us/step - loss: 2.0209 - accuracy: 0.2360 - val_loss: 2.1062 - val_accuracy: 0.2180\n"
     ]
    }
   ],
   "source": [
    "filepath=\"model4.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history4 = model4.fit(x_train_1[1:10000], to_categorical(y_train[1:10000]), batch_size = 16, epochs = 4, validation_split = .1,callbacks=[checkpointer])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating The model\n",
    "\n",
    "Here i am using sklearn model evaluate to test the accurcay of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "armdgCYBCcqr",
    "outputId": "11775275-3746-4c17-c7ff-6ab5485d079f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 52us/step\n",
      "[2.29589410832723, 0.1970333307981491]\n"
     ]
    }
   ],
   "source": [
    "score1 = model1.evaluate(x_test_1, to_categorical(y_test), verbose=1)\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "afT7YZiY7djF",
    "outputId": "cfe2d371-61b6-4ab8-b74e-fb75db7de8cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 36us/step\n",
      "[2.098565194129944, 0.21246667206287384]\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(x_test_1, to_categorical(y_test), verbose=1)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "64BEsAaX78vI",
    "outputId": "93e40202-547c-4788-c3e4-49e19e255877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 42us/step\n",
      "[2.0422845794677733, 0.22183333337306976]\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.evaluate(x_test_1, to_categorical(y_test), verbose=1)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "H6BqxKgR78vV",
    "outputId": "d2db50b5-5864-4cb1-8a80-4b4886b1abc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 59us/step\n",
      "[2.092603381093343, 0.21591666340827942]\n"
     ]
    }
   ],
   "source": [
    "score4 = model4.evaluate(x_test_1, to_categorical(y_test), verbose=1)\n",
    "print(score4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "\n",
    "Here I am saving all the models as h5 files so that i can use them to again without training them. Also I need to save my tokenizer or vocabulary so that any new sentence can be processed before feeding into the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_ZUjsD3EgGq"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "odel1.save(\"/content/drive/My Drive/model1.h5\")\n",
    "model2.save(\"/content/drive/My Drive/model2.h5\")\n",
    "model3.save(\"/content/drive/My Drive/model3.h5\")\n",
    "model4.save(\"/content/drive/My Drive/model4.h5\")\n",
    "with open('/content/drive/My Drive/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing the Results\n",
    "\n",
    "I am using matplot lib to visualize all my accuracy for the best model . Which is the CNN with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "RNtTJutJFcKv",
    "outputId": "7f71c7c4-33ae-4bb9-830e-b22efdd5e99e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epoch')"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4.history['accuracy'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "ORGSKBlyG9qL",
    "outputId": "dffe3505-433a-42a3-f5df-05993788aeff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6bd6b804a8>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history4.history['loss'])\n",
    "plt.plot(history4.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "7eOSikSXHGJU",
    "outputId": "2aa32b16-f5e5-4a65-ea00-7373a06fe28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.61      0.32      6021\n",
      "           1       0.26      0.07      0.12      5968\n",
      "           2       0.19      0.07      0.10      5946\n",
      "           3       0.16      0.21      0.18      6001\n",
      "           4       0.19      0.09      0.13      6036\n",
      "           5       0.18      0.15      0.16      5966\n",
      "           6       0.19      0.26      0.22      6019\n",
      "           7       0.23      0.08      0.12      5990\n",
      "           8       0.19      0.13      0.15      6035\n",
      "           9       0.31      0.48      0.38      6018\n",
      "\n",
      "    accuracy                           0.22     60000\n",
      "   macro avg       0.21      0.22      0.19     60000\n",
      "weighted avg       0.21      0.22      0.19     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, np.argmax(model4.predict(x_test_1),axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "I would say that my neural network model did not perform well enough as i expected. However CNN works better as compared to dense neural networks. There are better models present like RNN and LSTM but due to the computational power i was not able to implement them.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BoarGameGeekReview-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
